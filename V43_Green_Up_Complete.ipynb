{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tristanhowells/MNIST/blob/main/V43_Green_Up_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJJgU1KZaHm",
        "outputId": "3660b9c4-3e82-474a-8400-0e42f4de004a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### CELL 1 - GOOGLE DRIVE SETUP ###\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPSkWEsbZaHn",
        "outputId": "235b581c-69c5-4d67-d644-eed115265498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/188.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m184.3/188.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "### CELL 2 - INSTALL DEPENDENCIES ###\n",
        "\n",
        "!pip install stable-baselines3[extra] gymnasium shimmy pandas numpy pyarrow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZgslt00ZaHo",
        "outputId": "560f922e-e0c5-48e3-e019-636444fce4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "V43 Configuration - Full Feature Set + Green-up\n",
            "============================================================\n",
            "\n",
            "‚úÖ Configuration loaded for V43\n",
            "\n",
            "üìä Feature Set:\n",
            "   Observation dimensions: 755 (vs V42's 323)\n",
            "   Runner features: 31 (vs V42's 13)\n",
            "   Unused features from V42: 18\n",
            "\n",
            "üéØ New Features:\n",
            "   ‚Ä¢ Order book depth (levels 2-3): 8 features\n",
            "   ‚Ä¢ Pre-calculated volatility: 2 features\n",
            "   ‚Ä¢ Pre-calculated ob_imbalance: 1 feature\n",
            "   ‚Ä¢ Pre-calculated rel_spread: 1 feature\n",
            "   ‚Ä¢ Direct prob_implied: 1 feature\n",
            "   ‚Ä¢ Trading activity: 2 features\n",
            "   ‚Ä¢ Data quality: 3 features\n",
            "   ‚Ä¢ Engineered depth metrics: 3 features\n",
            "\n",
            "üí∞ Capital: $1000\n",
            "   Commission: 2.0%\n",
            "   Reserve ratio: 20.0%\n",
            "\n",
            "üéì Curriculum: 20,000 warmup ‚Üí 200,000 total\n",
            "   Min liability: $0.05 ‚Üí $5.0\n",
            "   Action threshold: 0.01 ‚Üí 0.3\n",
            "\n",
            "üõ°Ô∏è  Safety Constraints:\n",
            "   Min depth ratio: 50.0%\n",
            "   High volatility threshold: 0.05\n",
            "   Stale market threshold: 60s\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "### CELL 3 - CONFIGURATION (V43 - FULL FEATURE SET) ###\n",
        "\n",
        "# V43: All Features + Green-up Strategy\n",
        "# 755-dimensional observation space (vs V42's 323)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"V43 Configuration - Full Feature Set + Green-up\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# PATHS\n",
        "# ============================================================\n",
        "BASE_PATH = '/content/drive/MyDrive/Betfair_RL/V43_Full_Features'\n",
        "DATA_DIR = '/content/drive/MyDrive/race_out'\n",
        "\n",
        "import os\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# HYPERPARAMETERS - SAC\n",
        "# ============================================================\n",
        "SAC_LEARNING_RATE = 3e-4\n",
        "SAC_BUFFER_SIZE = 100000\n",
        "SAC_LEARNING_STARTS = 1000\n",
        "SAC_BATCH_SIZE = 256\n",
        "SAC_TAU = 0.005\n",
        "SAC_GAMMA = 0.99\n",
        "SAC_TRAIN_FREQ = 1\n",
        "SAC_GRADIENT_STEPS = 1\n",
        "SAC_ENT_COEF = 'auto'\n",
        "\n",
        "# ============================================================\n",
        "# ENVIRONMENT PARAMETERS\n",
        "# ============================================================\n",
        "MAX_CAPITAL = 1000.0\n",
        "COMMISSION_RATE = 0.02  # 2% (training rate)\n",
        "\n",
        "# Curriculum Learning\n",
        "CURRICULUM_TOTAL_STEPS = 200000\n",
        "CURRICULUM_WARMUP_STEPS = 20000\n",
        "\n",
        "# V43: Graduated constraints (same as V42)\n",
        "INITIAL_MIN_LIABILITY = 0.05      # Start very permissive\n",
        "PRODUCTION_MIN_LIABILITY = 5.0     # End strict\n",
        "INITIAL_ACTION_THRESHOLD = 0.01    # Start very permissive\n",
        "PRODUCTION_ACTION_THRESHOLD = 0.3  # End strict\n",
        "\n",
        "# Capital Management\n",
        "RESERVE_RATIO = 0.20                # 20% capital reserve\n",
        "MAX_EXPOSURE_MULTIPLIER = 1.5       # Can use 150% of available (with reserve)\n",
        "\n",
        "# Rewards (same as V42)\n",
        "STEP_REWARD_TRADE = 0.01\n",
        "STEP_REWARD_NO_TRADE = -0.001\n",
        "MTM_REWARD_SCALE = 5.0\n",
        "SHARPE_REWARD_SCALE = 1.0\n",
        "CAPITAL_PRESERVATION_BONUS = 0.1\n",
        "\n",
        "# V43: New - Depth and volatility constraints\n",
        "MIN_DEPTH_RATIO = 0.5              # Trade must be <50% of available depth\n",
        "HIGH_VOLATILITY_THRESHOLD = 0.05   # ret_std_5s threshold\n",
        "STALE_MARKET_THRESHOLD = 60        # secs_since_last_trade threshold\n",
        "\n",
        "print(f\"\\n‚úÖ Configuration loaded for V43\")\n",
        "print(f\"\\nüìä Feature Set:\")\n",
        "print(f\"   Observation dimensions: 755 (vs V42's 323)\")\n",
        "print(f\"   Runner features: 31 (vs V42's 13)\")\n",
        "print(f\"   Unused features from V42: 18\")\n",
        "print(f\"\\nüéØ New Features:\")\n",
        "print(f\"   ‚Ä¢ Order book depth (levels 2-3): 8 features\")\n",
        "print(f\"   ‚Ä¢ Pre-calculated volatility: 2 features\")\n",
        "print(f\"   ‚Ä¢ Pre-calculated ob_imbalance: 1 feature\")\n",
        "print(f\"   ‚Ä¢ Pre-calculated rel_spread: 1 feature\")\n",
        "print(f\"   ‚Ä¢ Direct prob_implied: 1 feature\")\n",
        "print(f\"   ‚Ä¢ Trading activity: 2 features\")\n",
        "print(f\"   ‚Ä¢ Data quality: 3 features\")\n",
        "print(f\"   ‚Ä¢ Engineered depth metrics: 3 features\")\n",
        "print(f\"\\nüí∞ Capital: ${MAX_CAPITAL:.0f}\")\n",
        "print(f\"   Commission: {COMMISSION_RATE*100}%\")\n",
        "print(f\"   Reserve ratio: {RESERVE_RATIO*100}%\")\n",
        "print(f\"\\nüéì Curriculum: {CURRICULUM_WARMUP_STEPS:,} warmup ‚Üí {CURRICULUM_TOTAL_STEPS:,} total\")\n",
        "print(f\"   Min liability: ${INITIAL_MIN_LIABILITY} ‚Üí ${PRODUCTION_MIN_LIABILITY}\")\n",
        "print(f\"   Action threshold: {INITIAL_ACTION_THRESHOLD} ‚Üí {PRODUCTION_ACTION_THRESHOLD}\")\n",
        "print(f\"\\nüõ°Ô∏è  Safety Constraints:\")\n",
        "print(f\"   Min depth ratio: {MIN_DEPTH_RATIO*100}%\")\n",
        "print(f\"   High volatility threshold: {HIGH_VOLATILITY_THRESHOLD}\")\n",
        "print(f\"   Stale market threshold: {STALE_MARKET_THRESHOLD}s\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CELL 4 - ENVIRONMENT & TRAINING COMPONENTS (V43 - FULL FEATURES) ###\n",
        "\n",
        "# V43 - Full Feature Set (755 dims) + Green-up Strategy\n",
        "# All 26 available features per runner\n",
        "# Depth checking, volatility-based sizing, quality filtering\n",
        "\n",
        "import random\n",
        "from collections import defaultdict, deque\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import warnings\n",
        "import signal\n",
        "import os\n",
        "\n",
        "class FileLoadTimeout(Exception):\n",
        "    \"\"\"Raised when file loading times out.\"\"\"\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise FileLoadTimeout(\"File loading timed out\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Model Version: V43_Full_Features_Green_Up\")\n",
        "print(\"Algorithm: SAC + ALL Features + Green-up\")\n",
        "print(\"\\n‚ú® Features:\")\n",
        "print(\"   ‚Ä¢ ALL 26 available features (100% utilization)\")\n",
        "print(\"   ‚Ä¢ 755-dimensional observation space\")\n",
        "print(\"   ‚Ä¢ Order book depth (levels 1-3)\")\n",
        "print(\"   ‚Ä¢ Pre-calculated volatility (ret_std_5s, ret_std_20s)\")\n",
        "print(\"   ‚Ä¢ Pre-calculated market metrics\")\n",
        "print(\"   ‚Ä¢ Trading activity signals\")\n",
        "print(\"   ‚Ä¢ Data quality indicators\")\n",
        "print(\"   ‚Ä¢ Green-up at in-play transition\")\n",
        "print(\"   ‚Ä¢ Depth-based trade filtering\")\n",
        "print(\"   ‚Ä¢ Volatility-based position sizing\")\n",
        "print(\"   ‚Ä¢ Stale market detection\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# TYPE-SAFE HELPERS\n",
        "# ============================================================\n",
        "\n",
        "def to_float(val, default=0.0):\n",
        "    \"\"\"Safely convert to float.\"\"\"\n",
        "    if val is None or val == '' or (isinstance(val, float) and np.isnan(val)):\n",
        "        return default\n",
        "    try:\n",
        "        return float(val)\n",
        "    except (ValueError, TypeError):\n",
        "        return default\n",
        "\n",
        "def safe_normalize(value, min_val, max_val, epsilon=1e-8):\n",
        "    \"\"\"Normalize to [0,1] with safety checks.\"\"\"\n",
        "    if max_val - min_val < epsilon:\n",
        "        return 0.5\n",
        "    normalized = (value - min_val) / (max_val - min_val)\n",
        "    return np.clip(normalized, 0.0, 1.0)\n",
        "\n",
        "def safe_log_norm(value, epsilon=1e-8):\n",
        "    \"\"\"Log-normalize with safety.\"\"\"\n",
        "    return np.log1p(max(0, value) + epsilon)\n",
        "\n",
        "# ============================================================\n",
        "# RUNNER DATA EXTRACTION (ALL 26 FEATURES!)\n",
        "# ============================================================\n",
        "\n",
        "def get_runner_data(row, runner_idx):\n",
        "    \"\"\"\n",
        "    V43: Extract ALL available features for a runner.\n",
        "    Returns 26 raw features per runner.\n",
        "    \"\"\"\n",
        "    prefix = f'run[{runner_idx}].'\n",
        "\n",
        "    try:\n",
        "        # === LEVEL 1: PRICES ===\n",
        "        back_1 = row.get(f'{prefix}back_price_1', None)\n",
        "        lay_1 = row.get(f'{prefix}lay_price_1', None)\n",
        "\n",
        "        if back_1 is None or lay_1 is None or pd.isna(back_1) or pd.isna(lay_1):\n",
        "            return None\n",
        "\n",
        "        # === LEVEL 1: VOLUMES ===\n",
        "        back_vol_1 = row.get(f'{prefix}back_size_1', 0.0)\n",
        "        lay_vol_1 = row.get(f'{prefix}lay_size_1', 0.0)\n",
        "\n",
        "        if pd.isna(back_vol_1):\n",
        "            back_vol_1 = 0.0\n",
        "        if pd.isna(lay_vol_1):\n",
        "            lay_vol_1 = 0.0\n",
        "\n",
        "        # === LEVEL 2: PRICES & VOLUMES ===\n",
        "        back_2 = row.get(f'{prefix}back_price_2', back_1)\n",
        "        lay_2 = row.get(f'{prefix}lay_price_2', lay_1)\n",
        "        back_vol_2 = row.get(f'{prefix}back_size_2', 0.0)\n",
        "        lay_vol_2 = row.get(f'{prefix}lay_size_2', 0.0)\n",
        "\n",
        "        if pd.isna(back_2): back_2 = back_1\n",
        "        if pd.isna(lay_2): lay_2 = lay_1\n",
        "        if pd.isna(back_vol_2): back_vol_2 = 0.0\n",
        "        if pd.isna(lay_vol_2): lay_vol_2 = 0.0\n",
        "\n",
        "        # === LEVEL 3: PRICES & VOLUMES ===\n",
        "        back_3 = row.get(f'{prefix}back_price_3', back_1)\n",
        "        lay_3 = row.get(f'{prefix}lay_price_3', lay_1)\n",
        "        back_vol_3 = row.get(f'{prefix}back_size_3', 0.0)\n",
        "        lay_vol_3 = row.get(f'{prefix}lay_size_3', 0.0)\n",
        "\n",
        "        if pd.isna(back_3): back_3 = back_1\n",
        "        if pd.isna(lay_3): lay_3 = lay_1\n",
        "        if pd.isna(back_vol_3): back_vol_3 = 0.0\n",
        "        if pd.isna(lay_vol_3): lay_vol_3 = 0.0\n",
        "\n",
        "        # === DATA QUALITY INDICATORS ===\n",
        "        has_level_1 = row.get(f'{prefix}has_level_1', True)\n",
        "        has_level_2 = row.get(f'{prefix}has_level_2', False)\n",
        "        has_level_3 = row.get(f'{prefix}has_level_3', False)\n",
        "\n",
        "        if pd.isna(has_level_1): has_level_1 = True\n",
        "        if pd.isna(has_level_2): has_level_2 = False\n",
        "        if pd.isna(has_level_3): has_level_3 = False\n",
        "\n",
        "        # === LAST TRADED ===\n",
        "        ltp = row.get(f'{prefix}last_traded_price', back_1)\n",
        "        if pd.isna(ltp):\n",
        "            ltp = back_1\n",
        "\n",
        "        # === TRADED VOLUME ===\n",
        "        traded_vol_total = row.get(f'{prefix}traded_vol_total', 0.0)\n",
        "        if pd.isna(traded_vol_total):\n",
        "            traded_vol_total = 0.0\n",
        "\n",
        "        traded_vol_60s = row.get(f'{prefix}traded_vol_60s', 0.0)\n",
        "        if pd.isna(traded_vol_60s):\n",
        "            traded_vol_60s = 0.0\n",
        "\n",
        "        # === TIME SINCE LAST TRADE ===\n",
        "        secs_since_last_trade = row.get(f'{prefix}secs_since_last_trade', 999.0)\n",
        "        if pd.isna(secs_since_last_trade):\n",
        "            secs_since_last_trade = 999.0\n",
        "\n",
        "        # === PRE-CALCULATED FEATURES ===\n",
        "        microprice = row.get(f'{prefix}microprice', None)\n",
        "        if microprice is None or pd.isna(microprice):\n",
        "            microprice = (back_1 + lay_1) / 2.0\n",
        "\n",
        "        ob_imbalance = row.get(f'{prefix}ob_imbalance', None)\n",
        "        if ob_imbalance is None or pd.isna(ob_imbalance):\n",
        "            # Fallback: calculate simple level-1 imbalance\n",
        "            total_vol = back_vol_1 + lay_vol_1\n",
        "            if total_vol > 0:\n",
        "                ob_imbalance = (back_vol_1 - lay_vol_1) / total_vol\n",
        "            else:\n",
        "                ob_imbalance = 0.0\n",
        "\n",
        "        rel_spread = row.get(f'{prefix}rel_spread', None)\n",
        "        if rel_spread is None or pd.isna(rel_spread):\n",
        "            # Fallback: calculate\n",
        "            spread = abs(back_1 - lay_1)\n",
        "            rel_spread = spread / max(microprice, 1.01)\n",
        "\n",
        "        prob_implied = row.get(f'{prefix}prob_implied', None)\n",
        "        if prob_implied is None or pd.isna(prob_implied):\n",
        "            # Fallback: use WOM\n",
        "            total_vol = back_vol_1 + lay_vol_1\n",
        "            if total_vol > 0:\n",
        "                prob_implied = back_vol_1 / total_vol\n",
        "            else:\n",
        "                prob_implied = 1.0 / microprice if microprice > 1.01 else 0.5\n",
        "\n",
        "        # === VOLATILITY (PRE-CALCULATED) ===\n",
        "        ret_std_5s = row.get(f'{prefix}ret_std_5s', 0.0)\n",
        "        if pd.isna(ret_std_5s):\n",
        "            ret_std_5s = 0.0\n",
        "\n",
        "        ret_std_20s = row.get(f'{prefix}ret_std_20s', 0.0)\n",
        "        if pd.isna(ret_std_20s):\n",
        "            ret_std_20s = 0.0\n",
        "\n",
        "        # === RETURN ALL 26 FEATURES ===\n",
        "        return {\n",
        "            # Level 1 (4)\n",
        "            'back_1': float(back_1),\n",
        "            'lay_1': float(lay_1),\n",
        "            'back_vol_1': float(back_vol_1),\n",
        "            'lay_vol_1': float(lay_vol_1),\n",
        "\n",
        "            # Level 2 (4)\n",
        "            'back_2': float(back_2),\n",
        "            'lay_2': float(lay_2),\n",
        "            'back_vol_2': float(back_vol_2),\n",
        "            'lay_vol_2': float(lay_vol_2),\n",
        "\n",
        "            # Level 3 (4)\n",
        "            'back_3': float(back_3),\n",
        "            'lay_3': float(lay_3),\n",
        "            'back_vol_3': float(back_vol_3),\n",
        "            'lay_vol_3': float(lay_vol_3),\n",
        "\n",
        "            # Data quality (3)\n",
        "            'has_level_1': bool(has_level_1),\n",
        "            'has_level_2': bool(has_level_2),\n",
        "            'has_level_3': bool(has_level_3),\n",
        "\n",
        "            # Trading activity (4)\n",
        "            'ltp': float(ltp),\n",
        "            'traded_vol_total': float(traded_vol_total),\n",
        "            'traded_vol_60s': float(traded_vol_60s),\n",
        "            'secs_since_last_trade': float(secs_since_last_trade),\n",
        "\n",
        "            # Pre-calculated features (5)\n",
        "            'microprice': float(microprice),\n",
        "            'ob_imbalance': float(ob_imbalance),\n",
        "            'rel_spread': float(rel_spread),\n",
        "            'prob_implied': float(prob_implied),\n",
        "\n",
        "            # Volatility (2)\n",
        "            'ret_std_5s': float(ret_std_5s),\n",
        "            'ret_std_20s': float(ret_std_20s),\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "# ============================================================\n",
        "# CURRICULUM TRACKER (same as V42)\n",
        "# ============================================================\n",
        "\n",
        "class CurriculumTracker:\n",
        "    \"\"\"Graduated MIN_LIABILITY and ACTION_THRESHOLD.\"\"\"\n",
        "\n",
        "    def __init__(self, total_steps, warmup_steps):\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.current_step = 0\n",
        "\n",
        "        self.min_liability_start = INITIAL_MIN_LIABILITY\n",
        "        self.min_liability_end = PRODUCTION_MIN_LIABILITY\n",
        "\n",
        "        self.threshold_start = INITIAL_ACTION_THRESHOLD\n",
        "        self.threshold_end = PRODUCTION_ACTION_THRESHOLD\n",
        "\n",
        "    def step(self):\n",
        "        self.current_step += 1\n",
        "\n",
        "    def get_progress(self):\n",
        "        \"\"\"Quadratic ease-in curve.\"\"\"\n",
        "        if self.current_step < self.warmup_steps:\n",
        "            return 0.0\n",
        "\n",
        "        effective_step = self.current_step - self.warmup_steps\n",
        "        effective_total = self.total_steps - self.warmup_steps\n",
        "\n",
        "        if effective_step >= effective_total:\n",
        "            return 1.0\n",
        "\n",
        "        linear_progress = effective_step / effective_total\n",
        "        return linear_progress ** 2\n",
        "\n",
        "    def get_current_min_liability(self):\n",
        "        progress = self.get_progress()\n",
        "        return self.min_liability_start + (self.min_liability_end - self.min_liability_start) * progress\n",
        "\n",
        "    def get_current_action_threshold(self):\n",
        "        progress = self.get_progress()\n",
        "        return self.threshold_start + (self.threshold_end - self.threshold_start) * progress\n",
        "\n",
        "    def get_status_string(self):\n",
        "        progress = self.get_progress() * 100\n",
        "        min_lia = self.get_current_min_liability()\n",
        "        threshold = self.get_current_action_threshold()\n",
        "        return f\"Curriculum: {progress:.0f}% | MIN_LIA=${min_lia:.2f} | Œ∏={threshold:.3f}\"\n",
        "\n",
        "# ============================================================\n",
        "# MARKET MAKING ENVIRONMENT (V43 - ALL FEATURES)\n",
        "# ============================================================\n",
        "\n",
        "class MarketMakingEnv(gym.Env):\n",
        "    \"\"\"V43: Full feature set (755 dims) + Green-up strategy.\"\"\"\n",
        "\n",
        "    metadata = {'render_modes': ['human']}\n",
        "\n",
        "    def __init__(self, race_files, curriculum_tracker=None):\n",
        "        super().__init__()\n",
        "\n",
        "        print(f\"\\n[ENV INIT] V43 with ALL features (755 dimensions)\")\n",
        "\n",
        "        self.race_files = race_files\n",
        "        self.curriculum_tracker = curriculum_tracker\n",
        "\n",
        "        if self.curriculum_tracker:\n",
        "            print(f\"[ENV] Curriculum tracker attached ‚úÖ\")\n",
        "        else:\n",
        "            print(f\"[ENV] No curriculum (fixed constraints)\")\n",
        "\n",
        "        # Action: 24 runner signals + 1 allocation\n",
        "        self.action_space = spaces.Box(\n",
        "            low=-1.0, high=1.0, shape=(25,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # V43: 755-dimensional observation space\n",
        "        # 24 runners √ó 31 features + 11 global = 755\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(755,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Episode state\n",
        "        self.current_race_df = None\n",
        "        self.runner_count = 0\n",
        "        self.step_idx = 0\n",
        "\n",
        "        # Financial state\n",
        "        self.balance = MAX_CAPITAL\n",
        "        self.initial_balance = MAX_CAPITAL\n",
        "        self.positions = {}\n",
        "        self.total_commission_paid = 0.0\n",
        "        self.total_mtm_reward = 0.0\n",
        "        self.total_sharpe_reward = 0.0\n",
        "\n",
        "        # Tracking\n",
        "        self.trades_this_episode = []\n",
        "        self.trades_last_10_steps = deque(maxlen=10)\n",
        "        self.price_history = deque(maxlen=20)\n",
        "\n",
        "        # MTM and Sharpe tracking\n",
        "        self.previous_mtm_pnl = 0.0\n",
        "        self.pnl_history = deque(maxlen=100)\n",
        "        self.peak_balance = MAX_CAPITAL\n",
        "\n",
        "        # Episode counter\n",
        "        self.episode_number = 0\n",
        "\n",
        "        # V43: Track depth violations for debugging\n",
        "        self.depth_violations = 0\n",
        "        self.volatility_violations = 0\n",
        "        self.stale_market_violations = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.episode_number += 1\n",
        "\n",
        "        # Load random race\n",
        "        max_attempts = 5\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                race_file = random.choice(self.race_files)\n",
        "                self.current_race_df = pd.read_parquet(race_file)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                if attempt == max_attempts - 1:\n",
        "                    raise RuntimeError(f\"Failed after {max_attempts} attempts\")\n",
        "                try:\n",
        "                    if race_file in self.race_files:\n",
        "                        self.race_files.remove(race_file)\n",
        "                        print(f\"‚ö†Ô∏è  Skipping corrupt file\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        self.runner_count = int(to_float(self.current_race_df.iloc[0]['runner_count'], 9))\n",
        "        self.step_idx = 0\n",
        "        self.positions = {}\n",
        "        self.balance = MAX_CAPITAL\n",
        "        self.initial_balance = MAX_CAPITAL\n",
        "        self.total_commission_paid = 0.0\n",
        "        self.trades_this_episode = []\n",
        "        self.trades_last_10_steps.clear()\n",
        "        self.price_history.clear()\n",
        "\n",
        "        # Reset MTM tracking\n",
        "        self.previous_mtm_pnl = 0.0\n",
        "        self.pnl_history.clear()\n",
        "        self.peak_balance = MAX_CAPITAL\n",
        "        self.total_mtm_reward = 0.0\n",
        "        self.total_sharpe_reward = 0.0\n",
        "\n",
        "        # V43: Reset violation counters\n",
        "        self.depth_violations = 0\n",
        "        self.volatility_violations = 0\n",
        "        self.stale_market_violations = 0\n",
        "\n",
        "        return self._get_observation(), {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        V43: Build 755-dimensional observation with ALL features.\n",
        "        24 runners √ó 31 features + 11 global = 755 dims\n",
        "        \"\"\"\n",
        "        if self.step_idx >= len(self.current_race_df):\n",
        "            return np.zeros(755, dtype=np.float32)\n",
        "\n",
        "        row = self.current_race_df.iloc[self.step_idx]\n",
        "        obs = []\n",
        "\n",
        "        # RUNNER OBSERVATIONS (31 features √ó 24 runners = 744)\n",
        "        for runner_idx in range(24):\n",
        "            if runner_idx < self.runner_count:\n",
        "                runner_data = get_runner_data(row, runner_idx)\n",
        "\n",
        "                if runner_data:\n",
        "                    # === LEVEL 1: PRICES & VOLUMES (4 features) ===\n",
        "                    back_1 = safe_normalize(runner_data['back_1'], 1.01, 1000.0)\n",
        "                    lay_1 = safe_normalize(runner_data['lay_1'], 1.01, 1000.0)\n",
        "                    back_vol_1 = safe_log_norm(runner_data['back_vol_1'])\n",
        "                    lay_vol_1 = safe_log_norm(runner_data['lay_vol_1'])\n",
        "\n",
        "                    # === LEVEL 2: PRICES & VOLUMES (4 features) ===\n",
        "                    back_2 = safe_normalize(runner_data['back_2'], 1.01, 1000.0)\n",
        "                    lay_2 = safe_normalize(runner_data['lay_2'], 1.01, 1000.0)\n",
        "                    back_vol_2 = safe_log_norm(runner_data['back_vol_2'])\n",
        "                    lay_vol_2 = safe_log_norm(runner_data['lay_vol_2'])\n",
        "\n",
        "                    # === LEVEL 3: PRICES & VOLUMES (4 features) ===\n",
        "                    back_3 = safe_normalize(runner_data['back_3'], 1.01, 1000.0)\n",
        "                    lay_3 = safe_normalize(runner_data['lay_3'], 1.01, 1000.0)\n",
        "                    back_vol_3 = safe_log_norm(runner_data['back_vol_3'])\n",
        "                    lay_vol_3 = safe_log_norm(runner_data['lay_vol_3'])\n",
        "\n",
        "                    # === PRE-CALCULATED FEATURES (6 features) ===\n",
        "                    microprice = safe_normalize(runner_data['microprice'], 1.01, 1000.0)\n",
        "                    ob_imbalance = safe_normalize(runner_data['ob_imbalance'], -1.0, 1.0)\n",
        "                    rel_spread = safe_normalize(runner_data['rel_spread'], 0.0, 0.1)\n",
        "                    prob_implied = safe_normalize(runner_data['prob_implied'], 0.0, 1.0)\n",
        "                    ret_std_5s = safe_log_norm(runner_data['ret_std_5s'])\n",
        "                    ret_std_20s = safe_log_norm(runner_data['ret_std_20s'])\n",
        "\n",
        "                    # === TRADING ACTIVITY (3 features) ===\n",
        "                    ltp = safe_normalize(runner_data['ltp'], 1.01, 1000.0)\n",
        "                    traded_vol_total = safe_log_norm(runner_data['traded_vol_total'])\n",
        "                    traded_vol_60s = safe_log_norm(runner_data['traded_vol_60s'])\n",
        "                    secs_since_last_trade = safe_log_norm(runner_data['secs_since_last_trade'] + 1)\n",
        "\n",
        "                    # === DATA QUALITY (3 features) ===\n",
        "                    has_level_1_f = float(runner_data['has_level_1'])\n",
        "                    has_level_2_f = float(runner_data['has_level_2'])\n",
        "                    has_level_3_f = float(runner_data['has_level_3'])\n",
        "\n",
        "                    # === ENGINEERED DEPTH FEATURES (3 features) ===\n",
        "                    # Total liquidity at each side\n",
        "                    total_back_liquidity = (runner_data['back_vol_1'] +\n",
        "                                           runner_data['back_vol_2'] +\n",
        "                                           runner_data['back_vol_3'])\n",
        "                    total_lay_liquidity = (runner_data['lay_vol_1'] +\n",
        "                                          runner_data['lay_vol_2'] +\n",
        "                                          runner_data['lay_vol_3'])\n",
        "\n",
        "                    total_back_liq_norm = safe_log_norm(total_back_liquidity)\n",
        "                    total_lay_liq_norm = safe_log_norm(total_lay_liquidity)\n",
        "\n",
        "                    # Depth concentration (how much is at level 1)\n",
        "                    if total_back_liquidity > 0:\n",
        "                        depth_concentration = runner_data['back_vol_1'] / total_back_liquidity\n",
        "                    else:\n",
        "                        depth_concentration = 1.0\n",
        "\n",
        "                    # Volume acceleration (recent vs total)\n",
        "                    if runner_data['traded_vol_total'] > 0:\n",
        "                        vol_acceleration = runner_data['traded_vol_60s'] / runner_data['traded_vol_total']\n",
        "                    else:\n",
        "                        vol_acceleration = 0.0\n",
        "                    vol_accel_norm = safe_normalize(vol_acceleration, 0.0, 1.0)\n",
        "\n",
        "                    # === POSITION TRACKING (2 features) ===\n",
        "                    net_position = self._get_net_position_stake(runner_idx) / MAX_CAPITAL\n",
        "                    position_pnl = self._get_position_pnl(runner_idx, runner_data['microprice']) / MAX_CAPITAL\n",
        "\n",
        "                    # === CUSTOM VOLATILITY (1 feature - kept from V42) ===\n",
        "                    if len(self.price_history) >= 2:\n",
        "                        recent_prices = [p.get(runner_idx, runner_data['microprice'])\n",
        "                                       for p in list(self.price_history)[-5:]]\n",
        "                        price_volatility = np.std(recent_prices) if len(recent_prices) > 1 else 0.0\n",
        "                    else:\n",
        "                        price_volatility = 0.0\n",
        "                    price_vol_norm = safe_log_norm(price_volatility)\n",
        "\n",
        "                    # === TOTAL: 31 FEATURES PER RUNNER ===\n",
        "                    obs.extend([\n",
        "                        # Level 1 (4)\n",
        "                        back_1, lay_1, back_vol_1, lay_vol_1,\n",
        "                        # Level 2 (4)\n",
        "                        back_2, lay_2, back_vol_2, lay_vol_2,\n",
        "                        # Level 3 (4)\n",
        "                        back_3, lay_3, back_vol_3, lay_vol_3,\n",
        "                        # Pre-calculated (6)\n",
        "                        microprice, ob_imbalance, rel_spread, prob_implied,\n",
        "                        ret_std_5s, ret_std_20s,\n",
        "                        # Trading activity (4)\n",
        "                        ltp, traded_vol_total, traded_vol_60s, secs_since_last_trade,\n",
        "                        # Data quality (3)\n",
        "                        has_level_1_f, has_level_2_f, has_level_3_f,\n",
        "                        # Engineered depth (3)\n",
        "                        total_back_liq_norm, total_lay_liq_norm, depth_concentration,\n",
        "                        # Volume (1)\n",
        "                        vol_accel_norm,\n",
        "                        # Position (2)\n",
        "                        net_position, position_pnl,\n",
        "                        # Custom volatility (1)\n",
        "                        price_vol_norm,\n",
        "                    ])\n",
        "                else:\n",
        "                    # No data for this runner\n",
        "                    obs.extend([0.0] * 31)\n",
        "            else:\n",
        "                # Runner index beyond runner_count\n",
        "                obs.extend([0.0] * 31)\n",
        "\n",
        "        # GLOBAL FEATURES (11 features)\n",
        "        current_exposure = self._get_total_exposure_with_liability()\n",
        "        available_capital = max(0.0, self.balance - current_exposure)\n",
        "        portfolio_mtm = self._get_total_unrealized_pnl()\n",
        "\n",
        "        obs.extend([\n",
        "            self.balance / MAX_CAPITAL,\n",
        "            current_exposure / MAX_CAPITAL,\n",
        "            available_capital / MAX_CAPITAL,\n",
        "            len(self.positions) / 24.0,\n",
        "            safe_normalize(self.step_idx, 0, len(self.current_race_df)),\n",
        "            self.total_commission_paid / MAX_CAPITAL,\n",
        "            len(self.trades_last_10_steps) / 10.0,\n",
        "            safe_normalize(self.runner_count, 2, 24),\n",
        "            self._get_total_net_exposure() / MAX_CAPITAL,\n",
        "            self._get_position_concentration(),\n",
        "            portfolio_mtm / MAX_CAPITAL\n",
        "        ])\n",
        "\n",
        "        # Verify dimension\n",
        "        assert len(obs) == 755, f\"Expected 755 dims, got {len(obs)}\"\n",
        "\n",
        "        return np.array(obs, dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        V43: LIABILITY-BASED with:\n",
        "        - Depth checking (prevent trade explosions)\n",
        "        - Volatility-based sizing\n",
        "        - Stale market filtering\n",
        "        - Green-up at in-play\n",
        "        \"\"\"\n",
        "\n",
        "        # Get curriculum settings\n",
        "        if self.curriculum_tracker is not None:\n",
        "            current_min_liability = self.curriculum_tracker.get_current_min_liability()\n",
        "            current_threshold = self.curriculum_tracker.get_current_action_threshold()\n",
        "            self.curriculum_tracker.step()\n",
        "        else:\n",
        "            current_min_liability = PRODUCTION_MIN_LIABILITY\n",
        "            current_threshold = PRODUCTION_ACTION_THRESHOLD\n",
        "\n",
        "        if self.step_idx >= len(self.current_race_df):\n",
        "            return self._get_observation(), 0.0, True, False, {}\n",
        "\n",
        "        # Decode action\n",
        "        runner_signals = action[:24]\n",
        "        allocation_raw = action[24]\n",
        "        allocation_pct = (allocation_raw + 1.0) / 2.0\n",
        "\n",
        "        # Capital reserve\n",
        "        current_exposure = self._get_total_exposure_with_liability()\n",
        "        unreserved_capital = max(0.0, self.balance - current_exposure)\n",
        "        available_capital = unreserved_capital * (1.0 - RESERVE_RATIO)\n",
        "        trade_budget = available_capital * allocation_pct * MAX_EXPOSURE_MULTIPLIER\n",
        "\n",
        "        # Execute trades with V43 safety checks\n",
        "        trades_executed = 0\n",
        "        current_row = self.current_race_df.iloc[self.step_idx]\n",
        "\n",
        "        # Store MTM before trades\n",
        "        mtm_before = self._get_total_unrealized_pnl()\n",
        "\n",
        "        for runner_idx in range(min(24, self.runner_count)):\n",
        "            signal = runner_signals[runner_idx]\n",
        "\n",
        "            # Signal threshold\n",
        "            if abs(signal) < current_threshold:\n",
        "                continue\n",
        "\n",
        "            runner_data = get_runner_data(current_row, runner_idx)\n",
        "            if runner_data is None:\n",
        "                continue\n",
        "\n",
        "            # === V43 SAFETY CHECK #1: DATA QUALITY ===\n",
        "            if not runner_data['has_level_1']:\n",
        "                # No level 1 data - skip this runner\n",
        "                continue\n",
        "\n",
        "            # === V43 SAFETY CHECK #2: STALE MARKET ===\n",
        "            if runner_data['secs_since_last_trade'] > STALE_MARKET_THRESHOLD:\n",
        "                # Market too quiet - prices may be stale\n",
        "                self.stale_market_violations += 1\n",
        "                continue\n",
        "\n",
        "            # === V43 SAFETY CHECK #3: HIGH VOLATILITY ===\n",
        "            if runner_data['ret_std_5s'] > HIGH_VOLATILITY_THRESHOLD:\n",
        "                # Volatile period - reduce position size\n",
        "                volatility_multiplier = 0.3\n",
        "                self.volatility_violations += 1\n",
        "            else:\n",
        "                volatility_multiplier = 1.0\n",
        "\n",
        "            side = 'BACK' if signal > 0 else 'LAY'\n",
        "            price = runner_data['back_1'] if side == 'BACK' else runner_data['lay_1']\n",
        "\n",
        "            if price < 1.01 or price > 1000:\n",
        "                continue\n",
        "\n",
        "            signal_strength = abs(signal)\n",
        "            runner_budget = trade_budget * signal_strength * volatility_multiplier\n",
        "\n",
        "            if runner_budget < current_min_liability:\n",
        "                continue\n",
        "\n",
        "            # === V43 SAFETY CHECK #4: DEPTH CHECKING ===\n",
        "            # Calculate available liquidity at all 3 levels\n",
        "            if side == 'BACK':\n",
        "                total_available = (runner_data['back_vol_1'] +\n",
        "                                  runner_data['back_vol_2'] +\n",
        "                                  runner_data['back_vol_3'])\n",
        "            else:\n",
        "                total_available = (runner_data['lay_vol_1'] +\n",
        "                                  runner_data['lay_vol_2'] +\n",
        "                                  runner_data['lay_vol_3'])\n",
        "\n",
        "            # Convert budget to stake equivalent\n",
        "            if side == 'BACK':\n",
        "                intended_stake = runner_budget\n",
        "            else:\n",
        "                intended_stake = runner_budget / (price - 1.0) if price > 1.01 else 0.0\n",
        "\n",
        "            # Don't trade if we'd consume too much of the available depth\n",
        "            if intended_stake > total_available * MIN_DEPTH_RATIO:\n",
        "                # Would consume >50% of depth - skip to prevent price impact\n",
        "                self.depth_violations += 1\n",
        "                continue\n",
        "\n",
        "            # Calculate actual liability (capped by depth and runner budget)\n",
        "            max_safe_stake = total_available * MIN_DEPTH_RATIO\n",
        "            liability = min(runner_budget, available_capital * 0.3)\n",
        "\n",
        "            # Further cap by depth\n",
        "            if side == 'BACK':\n",
        "                liability = min(liability, max_safe_stake)\n",
        "            else:\n",
        "                max_safe_liability = max_safe_stake * (price - 1.0)\n",
        "                liability = min(liability, max_safe_liability)\n",
        "\n",
        "            if liability < current_min_liability:\n",
        "                continue\n",
        "\n",
        "            success = self._execute_trade(runner_idx, side, liability, price)\n",
        "            if success:\n",
        "                trades_executed += 1\n",
        "\n",
        "        # Store prices for volatility calculation\n",
        "        prices = {}\n",
        "        for runner_idx in range(self.runner_count):\n",
        "            rd = get_runner_data(current_row, runner_idx)\n",
        "            if rd:\n",
        "                prices[runner_idx] = rd['microprice']\n",
        "        self.price_history.append(prices)\n",
        "\n",
        "        # Calculate rewards (same as V42)\n",
        "        mtm_after = self._get_total_unrealized_pnl()\n",
        "        mtm_change = mtm_after - mtm_before\n",
        "        mtm_reward = (mtm_change / MAX_CAPITAL) * MTM_REWARD_SCALE\n",
        "\n",
        "        self.pnl_history.append(mtm_change)\n",
        "        sharpe_reward = self._calculate_sharpe_reward()\n",
        "\n",
        "        self.total_mtm_reward += mtm_reward\n",
        "        self.total_sharpe_reward += sharpe_reward\n",
        "\n",
        "        capital_bonus = CAPITAL_PRESERVATION_BONUS if self.balance > (MAX_CAPITAL * 0.8) else 0.0\n",
        "        activity_reward = STEP_REWARD_TRADE if trades_executed > 0 else STEP_REWARD_NO_TRADE\n",
        "\n",
        "        step_reward = mtm_reward + sharpe_reward + capital_bonus + activity_reward\n",
        "\n",
        "        self.previous_mtm_pnl = mtm_after\n",
        "        self.peak_balance = max(self.peak_balance, self.balance)\n",
        "\n",
        "        self.step_idx += 1\n",
        "\n",
        "        # Check for in-play transition (green-up point)\n",
        "        reached_in_play = self._check_in_play_transition()\n",
        "\n",
        "        # Episode ends if: (1) in-play transition, or (2) data exhausted\n",
        "        done = reached_in_play or (self.step_idx >= len(self.current_race_df))\n",
        "\n",
        "        # Terminal reward\n",
        "        terminal_reward = 0.0\n",
        "        if done:\n",
        "            # Green up all positions\n",
        "            green_up_pnl = self._calculate_green_up_pnl()\n",
        "            self.balance += green_up_pnl\n",
        "            self.positions = {}\n",
        "            terminal_reward = green_up_pnl / MAX_CAPITAL\n",
        "\n",
        "        total_reward = step_reward + terminal_reward\n",
        "        obs = self._get_observation()\n",
        "\n",
        "        # Calculate max drawdown\n",
        "        max_drawdown = ((self.peak_balance - self.balance) / self.peak_balance) * 100 if self.peak_balance > 0 else 0.0\n",
        "\n",
        "        # Info dict\n",
        "        info = {\n",
        "            'trades_executed': trades_executed,\n",
        "            'final_balance': self.balance,\n",
        "            'final_pnl': self.balance - self.initial_balance,\n",
        "            'num_trades': len(self.trades_this_episode),\n",
        "            'mtm_reward': mtm_reward,\n",
        "            'sharpe_reward': sharpe_reward,\n",
        "            'total_mtm_reward': self.total_mtm_reward,\n",
        "            'total_sharpe_reward': self.total_sharpe_reward,\n",
        "            'max_drawdown': max_drawdown,\n",
        "            'depth_violations': self.depth_violations,\n",
        "            'volatility_violations': self.volatility_violations,\n",
        "            'stale_market_violations': self.stale_market_violations,\n",
        "        }\n",
        "\n",
        "        # Episode info for callbacks\n",
        "        if done:\n",
        "            info['episode'] = {\n",
        "                'r': total_reward,\n",
        "                'l': self.step_idx,\n",
        "                'realized_pnl': self.balance - self.initial_balance,\n",
        "                'num_trades': len(self.trades_this_episode),\n",
        "                'final_balance': self.balance,\n",
        "                'mtm_reward': self.total_mtm_reward,\n",
        "                'sharpe_reward': self.total_sharpe_reward,\n",
        "                'max_drawdown': max_drawdown,\n",
        "                'depth_violations': self.depth_violations,\n",
        "                'volatility_violations': self.volatility_violations,\n",
        "                'stale_market_violations': self.stale_market_violations,\n",
        "            }\n",
        "\n",
        "        return obs, total_reward, done, False, info\n",
        "\n",
        "    def _calculate_sharpe_reward(self):\n",
        "        \"\"\"Sharpe ratio component.\"\"\"\n",
        "        if len(self.pnl_history) < 10:\n",
        "            return 0.0\n",
        "\n",
        "        recent_pnl = list(self.pnl_history)[-20:]\n",
        "        mean_pnl = np.mean(recent_pnl)\n",
        "        std_pnl = np.std(recent_pnl)\n",
        "\n",
        "        if std_pnl < 1e-8:\n",
        "            return 0.0\n",
        "\n",
        "        sharpe = mean_pnl / std_pnl\n",
        "        sharpe_clipped = np.clip(sharpe, -3.0, 3.0)\n",
        "\n",
        "        return sharpe_clipped * SHARPE_REWARD_SCALE\n",
        "\n",
        "    def _get_total_unrealized_pnl(self):\n",
        "        \"\"\"Mark-to-market P&L.\"\"\"\n",
        "        if self.step_idx >= len(self.current_race_df):\n",
        "            return 0.0\n",
        "\n",
        "        current_row = self.current_race_df.iloc[self.step_idx]\n",
        "        total_mtm = 0.0\n",
        "\n",
        "        for runner_idx, pos in self.positions.items():\n",
        "            if abs(pos['net_stake']) < 1e-6:\n",
        "                continue\n",
        "\n",
        "            runner_data = get_runner_data(current_row, runner_idx)\n",
        "            if runner_data is None:\n",
        "                continue\n",
        "\n",
        "            current_price = runner_data['microprice']\n",
        "            mtm_pnl = self._get_position_pnl(runner_idx, current_price)\n",
        "            total_mtm += mtm_pnl\n",
        "\n",
        "        return total_mtm\n",
        "\n",
        "    def _execute_trade(self, runner_idx, side, liability, price):\n",
        "        \"\"\"Execute trade with position netting.\"\"\"\n",
        "\n",
        "        if side == 'BACK':\n",
        "            stake = liability\n",
        "        else:\n",
        "            stake = liability / (price - 1.0) if price > 1.01 else 0.0\n",
        "\n",
        "        if stake < 0.01:\n",
        "            return False\n",
        "\n",
        "        # Position netting\n",
        "        if runner_idx not in self.positions:\n",
        "            self.positions[runner_idx] = {\n",
        "                'net_stake': 0.0,\n",
        "                'weighted_price': 0.0,\n",
        "                'total_back_stake': 0.0,\n",
        "                'total_lay_liability': 0.0\n",
        "            }\n",
        "\n",
        "        pos = self.positions[runner_idx]\n",
        "\n",
        "        if side == 'BACK':\n",
        "            new_back = pos['total_back_stake'] + stake\n",
        "            if new_back > 0:\n",
        "                pos['weighted_price'] = (\n",
        "                    (pos['weighted_price'] * pos['total_back_stake'] + price * stake) / new_back\n",
        "                )\n",
        "            pos['total_back_stake'] = new_back\n",
        "            pos['net_stake'] += stake\n",
        "        else:\n",
        "            pos['total_lay_liability'] += liability\n",
        "            pos['net_stake'] -= stake\n",
        "            if pos['weighted_price'] == 0:\n",
        "                pos['weighted_price'] = price\n",
        "\n",
        "        # Logging\n",
        "        trade_info = {\n",
        "            'step': self.step_idx,\n",
        "            'runner': runner_idx,\n",
        "            'side': side,\n",
        "            'price': price,\n",
        "            'stake': stake,\n",
        "            'liability': liability\n",
        "        }\n",
        "        self.trades_this_episode.append(trade_info)\n",
        "        self.trades_last_10_steps.append(trade_info)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _check_in_play_transition(self):\n",
        "        \"\"\"Check if we've reached the in-play transition point.\"\"\"\n",
        "        if self.step_idx >= len(self.current_race_df):\n",
        "            return False\n",
        "\n",
        "        current_row = self.current_race_df.iloc[self.step_idx]\n",
        "\n",
        "        # Check seconds_to_start if available\n",
        "        seconds_to_start = current_row.get('seconds_to_start', None)\n",
        "        if seconds_to_start is not None:\n",
        "            return seconds_to_start <= 0\n",
        "\n",
        "        # Fallback: Use time-based threshold (last 5% of data)\n",
        "        total_steps = len(self.current_race_df)\n",
        "        in_play_threshold = int(total_steps * 0.95)\n",
        "        return self.step_idx >= in_play_threshold\n",
        "\n",
        "    def _calculate_green_up_pnl(self):\n",
        "        \"\"\"Calculate P&L from greening up all NET positions at current prices.\"\"\"\n",
        "        if not self.positions:\n",
        "            return 0.0\n",
        "\n",
        "        total_green_up_pnl = 0.0\n",
        "        current_row = self.current_race_df.iloc[self.step_idx]\n",
        "\n",
        "        for runner_idx, position in self.positions.items():\n",
        "            runner_data = get_runner_data(current_row, runner_idx)\n",
        "\n",
        "            if runner_data is None:\n",
        "                continue\n",
        "\n",
        "            net_stake = position.get('net_stake', 0.0)\n",
        "            weighted_price = position.get('weighted_price', 0.0)\n",
        "\n",
        "            if abs(net_stake) < 0.01 or weighted_price < 1.01:\n",
        "                continue\n",
        "\n",
        "            current_price = runner_data['microprice']\n",
        "\n",
        "            if current_price < 1.01:\n",
        "                continue\n",
        "\n",
        "            # Calculate green-up P&L\n",
        "            if net_stake > 0:\n",
        "                # NET BACK position\n",
        "                pnl = net_stake * (weighted_price - current_price) / current_price\n",
        "            else:\n",
        "                # NET LAY position\n",
        "                liability = abs(net_stake) * (weighted_price - 1)\n",
        "                pnl = liability * (1.0 / weighted_price - 1.0 / current_price)\n",
        "\n",
        "            # Apply commission on profitable green-ups only\n",
        "            if pnl > 0:\n",
        "                commission = pnl * COMMISSION_RATE\n",
        "                pnl_after_commission = pnl - commission\n",
        "            else:\n",
        "                pnl_after_commission = pnl\n",
        "\n",
        "            total_green_up_pnl += pnl_after_commission\n",
        "\n",
        "        return total_green_up_pnl\n",
        "\n",
        "    def _get_net_position_stake(self, runner_id):\n",
        "        if runner_id not in self.positions:\n",
        "            return 0.0\n",
        "        return self.positions[runner_id].get('net_stake', 0.0)\n",
        "\n",
        "    def _get_position_pnl(self, runner_id, current_price):\n",
        "        if runner_id not in self.positions:\n",
        "            return 0.0\n",
        "\n",
        "        pos = self.positions[runner_id]\n",
        "        net_stake = pos['net_stake']\n",
        "\n",
        "        if abs(net_stake) < 1e-6:\n",
        "            return 0.0\n",
        "\n",
        "        entry_price = pos['weighted_price']\n",
        "\n",
        "        if net_stake > 0:\n",
        "            pnl = net_stake * (current_price - entry_price)\n",
        "        else:\n",
        "            abs_stake = abs(net_stake)\n",
        "            pnl = abs_stake * (entry_price - current_price)\n",
        "\n",
        "        return pnl\n",
        "\n",
        "    def _get_total_exposure_with_liability(self):\n",
        "        total_exposure = 0.0\n",
        "\n",
        "        for runner_idx, pos in self.positions.items():\n",
        "            net_stake = pos['net_stake']\n",
        "            entry_price = pos['weighted_price']\n",
        "\n",
        "            if net_stake > 0:\n",
        "                total_exposure += abs(net_stake)\n",
        "            else:\n",
        "                abs_stake = abs(net_stake)\n",
        "                liability = abs_stake * (entry_price - 1.0) if entry_price > 1.0 else abs_stake\n",
        "                total_exposure += liability\n",
        "\n",
        "        return total_exposure\n",
        "\n",
        "    def _get_total_net_exposure(self):\n",
        "        return sum(pos['net_stake'] for pos in self.positions.values())\n",
        "\n",
        "    def _get_position_concentration(self):\n",
        "        if len(self.positions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        exposures = []\n",
        "        for pos in self.positions.values():\n",
        "            net_stake = pos['net_stake']\n",
        "            if abs(net_stake) > 1e-6:\n",
        "                exposures.append(abs(net_stake))\n",
        "\n",
        "        if len(exposures) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        total = sum(exposures)\n",
        "        if total < 1e-6:\n",
        "            return 0.0\n",
        "\n",
        "        proportions = [e / total for e in exposures]\n",
        "        herfindahl = sum(p**2 for p in proportions)\n",
        "\n",
        "        return herfindahl\n",
        "\n",
        "# ============================================================\n",
        "# NO-TRADE STREAK WRAPPER\n",
        "# ============================================================\n",
        "\n",
        "class NoTradeStreakWrapper(gym.Wrapper):\n",
        "    \"\"\"Penalize consecutive no-trade episodes.\"\"\"\n",
        "\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.consecutive_no_trade_episodes = 0\n",
        "        print(f\"[WRAPPER] NoTradeStreakWrapper initialized\")\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, truncated, info = self.env.step(action)\n",
        "\n",
        "        if done:\n",
        "            base_env = self.env\n",
        "            while hasattr(base_env, 'env'):\n",
        "                base_env = base_env.env\n",
        "\n",
        "            num_trades = len(base_env.trades_this_episode)\n",
        "            had_trades = num_trades > 0\n",
        "\n",
        "            if had_trades:\n",
        "                self.consecutive_no_trade_episodes = 0\n",
        "            else:\n",
        "                self.consecutive_no_trade_episodes += 1\n",
        "\n",
        "            if self.consecutive_no_trade_episodes > 0:\n",
        "                exponent = min(self.consecutive_no_trade_episodes - 1, 5)\n",
        "                penalty = -1.0 * (2 ** exponent)\n",
        "            else:\n",
        "                penalty = 0.0\n",
        "\n",
        "            reward = float(reward) + penalty\n",
        "\n",
        "            if 'episode' not in info:\n",
        "                info['episode'] = {}\n",
        "\n",
        "            info['episode']['no_trade_streak'] = self.consecutive_no_trade_episodes\n",
        "            info['episode']['no_trade_penalty'] = penalty\n",
        "            info['episode']['had_trades'] = had_trades\n",
        "            info['episode']['num_trades'] = num_trades\n",
        "            info['episode']['final_balance'] = info.get('final_balance', 1000.0)\n",
        "            info['episode']['final_pnl'] = info.get('final_pnl', 0.0)\n",
        "\n",
        "            info['no_trade_streak'] = self.consecutive_no_trade_episodes\n",
        "            info['no_trade_penalty'] = penalty\n",
        "            info['had_trades'] = had_trades\n",
        "            info['num_trades'] = num_trades\n",
        "            info['final_balance'] = info.get('final_balance', 1000.0)\n",
        "            info['final_pnl'] = info.get('final_pnl', 0.0)\n",
        "\n",
        "        return obs, reward, done, truncated, info\n",
        "\n",
        "# ============================================================\n",
        "# DATA LOADING\n",
        "# ============================================================\n",
        "\n",
        "def load_race_files(data_dir):\n",
        "    \"\"\"Load all parquet files with validation.\"\"\"\n",
        "    race_files = []\n",
        "    skipped_files = 0\n",
        "\n",
        "    print(f\"\\n[DATA] Loading parquet files from: {data_dir}\")\n",
        "\n",
        "    for file in os.listdir(data_dir):\n",
        "        if file.endswith('.parquet'):\n",
        "            filepath = os.path.join(data_dir, file)\n",
        "\n",
        "            try:\n",
        "                df = pd.read_parquet(filepath)\n",
        "\n",
        "                if len(df) < 10:\n",
        "                    skipped_files += 1\n",
        "                    continue\n",
        "\n",
        "                # Validation: Check for run[0].back_price_1 format\n",
        "                has_run0 = 'run[0].back_price_1' in df.columns\n",
        "\n",
        "                if not has_run0:\n",
        "                    if skipped_files < 3:\n",
        "                        print(f\"‚ö†Ô∏è  Skipping {file}: No run[0] columns found\")\n",
        "                    skipped_files += 1\n",
        "                    continue\n",
        "\n",
        "                race_files.append(filepath)\n",
        "\n",
        "            except Exception as e:\n",
        "                if skipped_files < 3:\n",
        "                    print(f\"‚ö†Ô∏è  Error loading {file}: {str(e)[:50]}\")\n",
        "                skipped_files += 1\n",
        "                continue\n",
        "\n",
        "    print(f\"[DATA] Loaded {len(race_files)} valid race files\")\n",
        "    if skipped_files > 0:\n",
        "        print(f\"[DATA] Skipped {skipped_files} invalid files\")\n",
        "\n",
        "    if len(race_files) == 0:\n",
        "        raise RuntimeError(\"No valid race files found!\")\n",
        "\n",
        "    return race_files\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING METRICS CALLBACK (V43)\n",
        "# ============================================================\n",
        "\n",
        "class TrainingMetricsCallback(BaseCallback):\n",
        "    \"\"\"V43: Track performance + violations.\"\"\"\n",
        "\n",
        "    def __init__(self, log_interval=1, save_path=None, curriculum_tracker=None):\n",
        "        super().__init__()\n",
        "        self.log_interval = log_interval\n",
        "        self.save_path = save_path\n",
        "        self.curriculum_tracker = curriculum_tracker\n",
        "        self.episode_count = 0\n",
        "        self.metrics = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.num_timesteps % 500 == 0:\n",
        "            print(f\"üîç Training callback alive at step {self.num_timesteps}, episodes: {self.episode_count}\")\n",
        "\n",
        "        dones = self.locals.get('dones', None)\n",
        "\n",
        "        if dones is None:\n",
        "            return True\n",
        "\n",
        "        if isinstance(dones, np.ndarray):\n",
        "            episode_done = bool(dones[0])\n",
        "        elif isinstance(dones, list):\n",
        "            episode_done = bool(dones[0])\n",
        "        else:\n",
        "            episode_done = bool(dones)\n",
        "\n",
        "        if episode_done:\n",
        "            print(f\"üéØ Episode {self.episode_count + 1} completed at step {self.num_timesteps}\")\n",
        "            self.episode_count += 1\n",
        "\n",
        "            infos = self.locals.get('infos', [{}])\n",
        "            info = infos[0] if len(infos) > 0 else {}\n",
        "\n",
        "            env = self.training_env\n",
        "            while hasattr(env, 'env'):\n",
        "                env = env.env\n",
        "            if hasattr(env, 'envs'):\n",
        "                env = env.envs[0]\n",
        "                while hasattr(env, 'env'):\n",
        "                    env = env.env\n",
        "\n",
        "            # Read from info['episode'] first\n",
        "            if 'episode' in info and isinstance(info['episode'], dict):\n",
        "                episode_info = info['episode']\n",
        "                streak = episode_info.get('no_trade_streak', 0)\n",
        "                penalty = episode_info.get('no_trade_penalty', 0.0)\n",
        "                had_trades = episode_info.get('had_trades', False)\n",
        "                num_trades = episode_info.get('num_trades', 0)\n",
        "                final_balance = episode_info.get('final_balance', 1000.0)\n",
        "                final_pnl = episode_info.get('final_pnl', 0.0)\n",
        "                depth_violations = episode_info.get('depth_violations', 0)\n",
        "                volatility_violations = episode_info.get('volatility_violations', 0)\n",
        "                stale_market_violations = episode_info.get('stale_market_violations', 0)\n",
        "            else:\n",
        "                streak = info.get('no_trade_streak', 0)\n",
        "                penalty = info.get('no_trade_penalty', 0.0)\n",
        "                had_trades = info.get('had_trades', False)\n",
        "                num_trades = info.get('num_trades', 0)\n",
        "                final_balance = info.get('final_balance', 1000.0)\n",
        "                final_pnl = info.get('final_pnl', 0.0)\n",
        "                depth_violations = info.get('depth_violations', 0)\n",
        "                volatility_violations = info.get('volatility_violations', 0)\n",
        "                stale_market_violations = info.get('stale_market_violations', 0)\n",
        "\n",
        "            max_drawdown = (env.peak_balance - final_balance) / env.peak_balance if env.peak_balance > 0 else 0.0\n",
        "\n",
        "            if self.episode_count % self.log_interval == 0:\n",
        "                metrics = {\n",
        "                    'Episode': self.episode_count,\n",
        "                    'Step': self.num_timesteps,\n",
        "                    'Balance': final_balance,\n",
        "                    'Num_Trades': num_trades,\n",
        "                    'Realized_PnL': final_pnl,\n",
        "                    'No_Trade_Streak': streak,\n",
        "                    'No_Trade_Penalty': penalty,\n",
        "                    'Had_Trades': had_trades,\n",
        "                    'Max_Drawdown': max_drawdown,\n",
        "                    'MTM_Reward': info.get('total_mtm_reward', 0.0),\n",
        "                    'Sharpe_Reward': info.get('total_sharpe_reward', 0.0),\n",
        "                    'Depth_Violations': depth_violations,\n",
        "                    'Volatility_Violations': volatility_violations,\n",
        "                    'Stale_Market_Violations': stale_market_violations,\n",
        "                }\n",
        "\n",
        "                self.metrics.append(metrics)\n",
        "                print(f\"üìù Metrics collected: Episode {self.episode_count}\")\n",
        "\n",
        "                if self.episode_count % 10 == 0:\n",
        "                    recent = self.metrics[-10:]\n",
        "                    trade_rate = sum(1 for m in recent if m['Num_Trades'] > 0) / len(recent) * 100\n",
        "                    avg_pnl = np.mean([m['Realized_PnL'] for m in recent])\n",
        "                    avg_drawdown = np.mean([m['Max_Drawdown'] for m in recent])\n",
        "                    avg_depth_viol = np.mean([m['Depth_Violations'] for m in recent])\n",
        "                    avg_vol_viol = np.mean([m['Volatility_Violations'] for m in recent])\n",
        "\n",
        "                    print(f\"\\nüìä Ep {self.episode_count} | Step {self.num_timesteps:,}\")\n",
        "\n",
        "                    if self.curriculum_tracker is not None:\n",
        "                        print(f\"   {self.curriculum_tracker.get_status_string()}\")\n",
        "\n",
        "                    print(f\"   Trade Rate: {trade_rate:.0f}%\")\n",
        "                    print(f\"   Avg P&L: ${avg_pnl:.2f}\")\n",
        "                    print(f\"   Avg Drawdown: {avg_drawdown*100:.1f}%\")\n",
        "                    print(f\"   Avg Depth Violations: {avg_depth_viol:.1f}\")\n",
        "                    print(f\"   Avg Volatility Violations: {avg_vol_viol:.1f}\")\n",
        "\n",
        "                    if trade_rate > 0:\n",
        "                        traded = [m for m in recent if m['Num_Trades'] > 0]\n",
        "                        avg_trades = np.mean([m['Num_Trades'] for m in traded])\n",
        "                        print(f\"   Avg Trades/Race: {avg_trades:.1f}\")\n",
        "\n",
        "                if self.save_path:\n",
        "                    try:\n",
        "                        pd.DataFrame(self.metrics).to_csv(self.save_path, index=False)\n",
        "                        if self.episode_count % 10 == 0:\n",
        "                            print(f\"üíæ Saved {len(self.metrics)} episodes to CSV\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ùå Save failed: {str(e)}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "# ============================================================\n",
        "# VALIDATION CALLBACK (V43 - FIXED)\n",
        "# ============================================================\n",
        "\n",
        "class ValidationCallback(BaseCallback):\n",
        "    \"\"\"V43: Validation with proper unwrapping + violation tracking.\"\"\"\n",
        "\n",
        "    def __init__(self, val_env, val_interval=25000, save_path=None):\n",
        "        super().__init__()\n",
        "        self.val_env = val_env\n",
        "        self.val_interval = val_interval\n",
        "        self.save_path = save_path\n",
        "        self.val_metrics = []\n",
        "\n",
        "        # Create CSV file immediately\n",
        "        if self.save_path:\n",
        "            pd.DataFrame(columns=[\n",
        "                'Step', 'Val_Episode', 'Num_Trades', 'Realized_PnL',\n",
        "                'Final_Balance', 'MTM_Reward', 'Sharpe_Reward',\n",
        "                'Depth_Violations', 'Volatility_Violations', 'Stale_Market_Violations'\n",
        "            ]).to_csv(self.save_path, index=False)\n",
        "            print(f\"‚úÖ Validation CSV created: {self.save_path}\")\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        \"\"\"Run validation with proper environment unwrapping.\"\"\"\n",
        "        if self.num_timesteps % self.val_interval == 0 and self.num_timesteps > 0:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"üîç VALIDATION @ {self.num_timesteps:,} steps\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            val_results = []\n",
        "\n",
        "            for ep in range(10):\n",
        "                try:\n",
        "                    obs, _ = self.val_env.reset()\n",
        "                    done = False\n",
        "\n",
        "                    # Unwrap to get actual environment\n",
        "                    actual_env = self.val_env\n",
        "                    while hasattr(actual_env, 'env'):\n",
        "                        actual_env = actual_env.env\n",
        "\n",
        "                    # Run episode\n",
        "                    steps = 0\n",
        "                    while not done and steps < 2000:\n",
        "                        action, _ = self.model.predict(obs, deterministic=True)\n",
        "                        obs, reward, done, truncated, info = self.val_env.step(action)\n",
        "                        steps += 1\n",
        "                        done = done or truncated\n",
        "\n",
        "                    # Try to get from info['episode'] first\n",
        "                    if 'episode' in info:\n",
        "                        ep_info = info['episode']\n",
        "                        result = {\n",
        "                            'Step': self.num_timesteps,\n",
        "                            'Val_Episode': ep + 1,\n",
        "                            'Num_Trades': ep_info.get('num_trades', len(actual_env.trades_this_episode)),\n",
        "                            'Realized_PnL': ep_info.get('realized_pnl', actual_env.balance - actual_env.initial_balance),\n",
        "                            'Final_Balance': ep_info.get('final_balance', actual_env.balance),\n",
        "                            'MTM_Reward': ep_info.get('mtm_reward', 0.0),\n",
        "                            'Sharpe_Reward': ep_info.get('sharpe_reward', 0.0),\n",
        "                            'Depth_Violations': ep_info.get('depth_violations', 0),\n",
        "                            'Volatility_Violations': ep_info.get('volatility_violations', 0),\n",
        "                            'Stale_Market_Violations': ep_info.get('stale_market_violations', 0),\n",
        "                        }\n",
        "                    else:\n",
        "                        # Fallback to unwrapped environment\n",
        "                        result = {\n",
        "                            'Step': self.num_timesteps,\n",
        "                            'Val_Episode': ep + 1,\n",
        "                            'Num_Trades': len(actual_env.trades_this_episode),\n",
        "                            'Realized_PnL': actual_env.balance - actual_env.initial_balance,\n",
        "                            'Final_Balance': actual_env.balance,\n",
        "                            'MTM_Reward': getattr(actual_env, 'total_mtm_reward', 0.0),\n",
        "                            'Sharpe_Reward': getattr(actual_env, 'total_sharpe_reward', 0.0),\n",
        "                            'Depth_Violations': getattr(actual_env, 'depth_violations', 0),\n",
        "                            'Volatility_Violations': getattr(actual_env, 'volatility_violations', 0),\n",
        "                            'Stale_Market_Violations': getattr(actual_env, 'stale_market_violations', 0),\n",
        "                        }\n",
        "\n",
        "                    val_results.append(result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è  Val episode {ep+1} failed: {str(e)[:60]}\")\n",
        "                    continue\n",
        "\n",
        "            # Save and report results\n",
        "            if val_results:\n",
        "                df = pd.DataFrame(val_results)\n",
        "\n",
        "                # Append to CSV\n",
        "                if self.save_path:\n",
        "                    df.to_csv(self.save_path, mode='a', header=False, index=False)\n",
        "\n",
        "                # Print summary\n",
        "                trade_rate = (df['Num_Trades'] > 0).sum() / len(df) * 100\n",
        "                mean_pnl = df['Realized_PnL'].mean()\n",
        "                mean_trades = df['Num_Trades'].mean()\n",
        "                win_rate = (df['Realized_PnL'] > 0).sum() / len(df) * 100\n",
        "                mean_depth_viol = df['Depth_Violations'].mean()\n",
        "\n",
        "                print(f\"\\nüìä Validation Summary ({len(val_results)} episodes):\")\n",
        "                print(f\"   Mean P&L: ${mean_pnl:.2f}\")\n",
        "                print(f\"   Mean Trades: {mean_trades:.1f}\")\n",
        "                print(f\"   Win Rate: {win_rate:.1f}%\")\n",
        "                print(f\"   Trade Rate: {trade_rate:.1f}%\")\n",
        "                print(f\"   Avg Depth Violations: {mean_depth_viol:.1f}\")\n",
        "                print(f\"üíæ Saved to {self.save_path}\")\n",
        "            else:\n",
        "                print(f\"\\n‚ùå No validation results collected\")\n",
        "\n",
        "            print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "class CheckpointCallback(BaseCallback):\n",
        "    \"\"\"Save model checkpoints at regular intervals.\"\"\"\n",
        "\n",
        "    def __init__(self, save_freq, save_path):\n",
        "        super().__init__()\n",
        "        self.save_freq = save_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.num_timesteps % self.save_freq == 0 and self.num_timesteps > 0:\n",
        "            model_path = f\"{self.save_path}/model_{self.num_timesteps}\"\n",
        "            self.model.save(model_path)\n",
        "            print(f\"üíæ Model saved: {model_path}\")\n",
        "        return True\n",
        "\n",
        "print(\"\\n‚úÖ V43 Environment and callbacks loaded!\")\n",
        "print(\"‚úÖ 755-dimensional observation space\")\n",
        "print(\"‚úÖ All 26 features per runner\")\n",
        "print(\"‚úÖ Depth checking, volatility filtering, stale market detection\")\n",
        "print(\"‚úÖ Green-up strategy at in-play transition\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9UDAXKvPP8_",
        "outputId": "c7510e52-2714-4998-ae25-1110b5f4e211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Model Version: V43_Full_Features_Green_Up\n",
            "Algorithm: SAC + ALL Features + Green-up\n",
            "\n",
            "‚ú® Features:\n",
            "   ‚Ä¢ ALL 26 available features (100% utilization)\n",
            "   ‚Ä¢ 755-dimensional observation space\n",
            "   ‚Ä¢ Order book depth (levels 1-3)\n",
            "   ‚Ä¢ Pre-calculated volatility (ret_std_5s, ret_std_20s)\n",
            "   ‚Ä¢ Pre-calculated market metrics\n",
            "   ‚Ä¢ Trading activity signals\n",
            "   ‚Ä¢ Data quality indicators\n",
            "   ‚Ä¢ Green-up at in-play transition\n",
            "   ‚Ä¢ Depth-based trade filtering\n",
            "   ‚Ä¢ Volatility-based position sizing\n",
            "   ‚Ä¢ Stale market detection\n",
            "============================================================\n",
            "\n",
            "‚úÖ V43 Environment and callbacks loaded!\n",
            "‚úÖ 755-dimensional observation space\n",
            "‚úÖ All 26 features per runner\n",
            "‚úÖ Depth checking, volatility filtering, stale market detection\n",
            "‚úÖ Green-up strategy at in-play transition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CELL 5 - SETUP TRAINING (V43 - FULL FEATURES) ###\n",
        "\n",
        "# V43: All features + green-up strategy\n",
        "# 755-dimensional observations\n",
        "\n",
        "# Load race files\n",
        "print(\"\\nüìÇ Loading race files...\")\n",
        "train_files = load_race_files(DATA_DIR)\n",
        "val_files = train_files[-100:]  # Last 100 for validation\n",
        "train_files = train_files[:-100]  # Rest for training\n",
        "\n",
        "print(f\"Training files: {len(train_files)}\")\n",
        "print(f\"Validation files: {len(val_files)}\")\n",
        "\n",
        "# Create curriculum tracker\n",
        "print(\"\\nüìö Creating curriculum tracker...\")\n",
        "curriculum = CurriculumTracker(\n",
        "    total_steps=CURRICULUM_TOTAL_STEPS,\n",
        "    warmup_steps=CURRICULUM_WARMUP_STEPS\n",
        ")\n",
        "print(f\"‚úÖ Curriculum: {CURRICULUM_WARMUP_STEPS:,} warmup ‚Üí {CURRICULUM_TOTAL_STEPS:,} total\")\n",
        "\n",
        "# Create BARE environments (NO DummyVecEnv)\n",
        "print(\"\\nüîß Creating environments...\")\n",
        "\n",
        "# Training environment\n",
        "train_env = MarketMakingEnv(train_files, curriculum_tracker=curriculum)\n",
        "train_env = Monitor(train_env)\n",
        "train_env = NoTradeStreakWrapper(train_env)\n",
        "\n",
        "print(\"‚úÖ Training environment created\")\n",
        "print(\"   Wrapper order: NoTradeStreakWrapper ‚Üí Monitor ‚Üí MarketMakingEnv\")\n",
        "print(\"   Observation dims: 755\")\n",
        "\n",
        "# Validation environment (NO VecNormalize!)\n",
        "val_env = MarketMakingEnv(val_files, curriculum_tracker=None)\n",
        "val_env = Monitor(val_env)\n",
        "\n",
        "print(\"‚úÖ Validation environment created\")\n",
        "print(\"   Observation dims: 755\")\n",
        "\n",
        "# Create callbacks\n",
        "print(\"\\nüìä Setting up callbacks...\")\n",
        "\n",
        "training_callback = TrainingMetricsCallback(\n",
        "    log_interval=1,\n",
        "    save_path=f\"{BASE_PATH}/training_metrics.csv\",\n",
        "    curriculum_tracker=curriculum\n",
        ")\n",
        "\n",
        "validation_callback = ValidationCallback(\n",
        "    val_env=val_env,\n",
        "    val_interval=25000,\n",
        "    save_path=f\"{BASE_PATH}/validation_metrics.csv\"\n",
        ")\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=50000,\n",
        "    save_path=BASE_PATH\n",
        ")\n",
        "\n",
        "callbacks = CallbackList([\n",
        "    training_callback,\n",
        "    validation_callback,\n",
        "    checkpoint_callback\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Callbacks configured\")\n",
        "print(f\"   Training metrics: {BASE_PATH}/training_metrics.csv\")\n",
        "print(f\"   Validation metrics: {BASE_PATH}/validation_metrics.csv\")\n",
        "\n",
        "# Create SAC model\n",
        "print(\"\\nü§ñ Creating SAC model...\")\n",
        "\n",
        "model = SAC(\n",
        "    \"MlpPolicy\",\n",
        "    train_env,\n",
        "    learning_rate=SAC_LEARNING_RATE,\n",
        "    buffer_size=SAC_BUFFER_SIZE,\n",
        "    learning_starts=SAC_LEARNING_STARTS,\n",
        "    batch_size=SAC_BATCH_SIZE,\n",
        "    tau=SAC_TAU,\n",
        "    gamma=SAC_GAMMA,\n",
        "    train_freq=SAC_TRAIN_FREQ,\n",
        "    gradient_steps=SAC_GRADIENT_STEPS,\n",
        "    ent_coef=SAC_ENT_COEF,\n",
        "    verbose=1,\n",
        "    tensorboard_log=f\"{BASE_PATH}/logs\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ SAC model created\")\n",
        "print(f\"   Policy: MlpPolicy\")\n",
        "print(f\"   Observation dims: 755 (vs V42's 323)\")\n",
        "print(f\"   Learning rate: {SAC_LEARNING_RATE}\")\n",
        "print(f\"   Buffer size: {SAC_BUFFER_SIZE:,}\")\n",
        "print(f\"   Entropy coef: {SAC_ENT_COEF}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ V43 Setup complete - ready for training!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüéØ V43 Improvements over V42:\")\n",
        "print(\"   ‚Ä¢ 755 dims (vs 323): +133% more information\")\n",
        "print(\"   ‚Ä¢ Order book depth (levels 1-3): Prevent trade explosions\")\n",
        "print(\"   ‚Ä¢ Pre-calculated volatility: Better risk management\")\n",
        "print(\"   ‚Ä¢ Pre-calculated metrics: Better signals\")\n",
        "print(\"   ‚Ä¢ Depth checking: Block trades without liquidity\")\n",
        "print(\"   ‚Ä¢ Volatility filtering: Reduce position in chaos\")\n",
        "print(\"   ‚Ä¢ Stale market detection: Avoid outdated prices\")\n",
        "print(\"\\nüí° Expected improvements:\")\n",
        "print(\"   ‚Ä¢ Win rate: 18.5% ‚Üí 45-60%\")\n",
        "print(\"   ‚Ä¢ Trade explosions: 13.3% ‚Üí <3%\")\n",
        "print(\"   ‚Ä¢ Mean P&L: -$104 ‚Üí +$30-100\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avqw6OzpPQ6-",
        "outputId": "09f49a56-8d75-4d69-901d-658d3e66e73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Loading race files...\n",
            "\n",
            "[DATA] Loading parquet files from: /content/drive/MyDrive/race_out\n",
            "‚ö†Ô∏è  Error loading 2025-12-23_Ashburton_Race3_1.251967693.parquet: Could not open Parquet input source '<Buffer>': Co\n",
            "‚ö†Ô∏è  Error loading 2025-12-24_Ashburton_Race4_1.251967695.parquet: Corrupt snappy compressed data.\n",
            "[DATA] Loaded 3205 valid race files\n",
            "[DATA] Skipped 13 invalid files\n",
            "Training files: 3105\n",
            "Validation files: 100\n",
            "\n",
            "üìö Creating curriculum tracker...\n",
            "‚úÖ Curriculum: 20,000 warmup ‚Üí 200,000 total\n",
            "\n",
            "üîß Creating environments...\n",
            "\n",
            "[ENV INIT] V43 with ALL features (755 dimensions)\n",
            "[ENV] Curriculum tracker attached ‚úÖ\n",
            "[WRAPPER] NoTradeStreakWrapper initialized\n",
            "‚úÖ Training environment created\n",
            "   Wrapper order: NoTradeStreakWrapper ‚Üí Monitor ‚Üí MarketMakingEnv\n",
            "   Observation dims: 755\n",
            "\n",
            "[ENV INIT] V43 with ALL features (755 dimensions)\n",
            "[ENV] No curriculum (fixed constraints)\n",
            "‚úÖ Validation environment created\n",
            "   Observation dims: 755\n",
            "\n",
            "üìä Setting up callbacks...\n",
            "‚úÖ Validation CSV created: /content/drive/MyDrive/Betfair_RL/V43_Full_Features/validation_metrics.csv\n",
            "‚úÖ Callbacks configured\n",
            "   Training metrics: /content/drive/MyDrive/Betfair_RL/V43_Full_Features/training_metrics.csv\n",
            "   Validation metrics: /content/drive/MyDrive/Betfair_RL/V43_Full_Features/validation_metrics.csv\n",
            "\n",
            "ü§ñ Creating SAC model...\n",
            "Using cpu device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "‚úÖ SAC model created\n",
            "   Policy: MlpPolicy\n",
            "   Observation dims: 755 (vs V42's 323)\n",
            "   Learning rate: 0.0003\n",
            "   Buffer size: 100,000\n",
            "   Entropy coef: auto\n",
            "\n",
            "============================================================\n",
            "‚úÖ V43 Setup complete - ready for training!\n",
            "============================================================\n",
            "\n",
            "üéØ V43 Improvements over V42:\n",
            "   ‚Ä¢ 755 dims (vs 323): +133% more information\n",
            "   ‚Ä¢ Order book depth (levels 1-3): Prevent trade explosions\n",
            "   ‚Ä¢ Pre-calculated volatility: Better risk management\n",
            "   ‚Ä¢ Pre-calculated metrics: Better signals\n",
            "   ‚Ä¢ Depth checking: Block trades without liquidity\n",
            "   ‚Ä¢ Volatility filtering: Reduce position in chaos\n",
            "   ‚Ä¢ Stale market detection: Avoid outdated prices\n",
            "\n",
            "üí° Expected improvements:\n",
            "   ‚Ä¢ Win rate: 18.5% ‚Üí 45-60%\n",
            "   ‚Ä¢ Trade explosions: 13.3% ‚Üí <3%\n",
            "   ‚Ä¢ Mean P&L: -$104 ‚Üí +$30-100\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================================================\n",
        "# # CELL 5 - HELPER FUNCTIONS (FIXED FOR ACTUAL DATA STRUCTURE)\n",
        "# # ============================================================================\n",
        "# #\n",
        "# # DROP-IN REPLACEMENT for Cell 5\n",
        "# #\n",
        "# # FIXES APPLIED:\n",
        "# # - Maps to ACTUAL column names in your data\n",
        "# # - back_size_1/2/3 instead of back_vol_1/2/3\n",
        "# # - lay_size_1/2/3 instead of lay_vol_1/2/3\n",
        "# # - last_traded_price instead of ltp\n",
        "# # - Uses pre-calculated microprice, ob_imbalance, rel_spread\n",
        "# #\n",
        "# # ============================================================================\n",
        "\n",
        "# import numpy as np\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"üîß LOADING HELPER FUNCTIONS\")\n",
        "# print(\"=\"*80)\n",
        "\n",
        "# # Type-safe helpers\n",
        "# def to_float(val, default=0.0):\n",
        "#     \"\"\"Convert to float safely.\"\"\"\n",
        "#     try:\n",
        "#         if val is None or (isinstance(val, float) and np.isnan(val)):\n",
        "#             return default\n",
        "#         return float(val)\n",
        "#     except (ValueError, TypeError):\n",
        "#         return default\n",
        "\n",
        "# def safe_normalize(val, min_val, max_val):\n",
        "#     \"\"\"Normalize value to [0, 1] range.\"\"\"\n",
        "#     if val is None or val == 0.0:\n",
        "#         return 0.0\n",
        "#     val = max(min_val, min(max_val, val))\n",
        "#     return (val - min_val) / (max_val - min_val + 1e-8)\n",
        "\n",
        "# def safe_log_norm(val, default=0.0):\n",
        "#     \"\"\"Log-normalize value.\"\"\"\n",
        "#     if val is None or val <= 0:\n",
        "#         return default\n",
        "#     return np.log1p(val) / 10.0\n",
        "\n",
        "# # V41 column extraction (FIXED for actual data structure)\n",
        "# def get_runner_data(row, runner_idx):\n",
        "#     \"\"\"Extract runner data with run[idx] format.\n",
        "\n",
        "#     UPDATED to use actual column names:\n",
        "#     - back_size instead of back_vol\n",
        "#     - lay_size instead of lay_vol\n",
        "#     - last_traded_price instead of ltp\n",
        "#     - traded_vol_total instead of ltv\n",
        "#     - ob_imbalance instead of calculating wom\n",
        "#     - rel_spread (already calculated)\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         prefix = f'run[{runner_idx}].'\n",
        "\n",
        "#         # Check if runner exists\n",
        "#         back_col = f'{prefix}back_price_1'\n",
        "#         if back_col not in row.index:\n",
        "#             return None\n",
        "\n",
        "#         # Extract prices\n",
        "#         back_1 = to_float(row.get(f'{prefix}back_price_1'))\n",
        "#         lay_1 = to_float(row.get(f'{prefix}lay_price_1'))\n",
        "\n",
        "#         if back_1 <= 1.0 or lay_1 <= 1.0:\n",
        "#             return None\n",
        "\n",
        "#         # Volumes/Sizes - FIXED NAMES\n",
        "#         back_vol_1 = to_float(row.get(f'{prefix}back_size_1'), 0.0)\n",
        "#         lay_vol_1 = to_float(row.get(f'{prefix}lay_size_1'), 0.0)\n",
        "#         back_vol_2 = to_float(row.get(f'{prefix}back_size_2'), 0.0)\n",
        "#         lay_vol_2 = to_float(row.get(f'{prefix}lay_size_2'), 0.0)\n",
        "#         back_vol_3 = to_float(row.get(f'{prefix}back_size_3'), 0.0)\n",
        "#         lay_vol_3 = to_float(row.get(f'{prefix}lay_size_3'), 0.0)\n",
        "\n",
        "#         # Last traded - FIXED NAME\n",
        "#         ltp = to_float(row.get(f'{prefix}last_traded_price'), back_1)\n",
        "\n",
        "#         # Use pre-calculated microprice if available\n",
        "#         microprice = to_float(row.get(f'{prefix}microprice'))\n",
        "#         if microprice <= 0:\n",
        "#             # Fallback: calculate if not available\n",
        "#             total_vol = back_vol_1 + lay_vol_1\n",
        "#             if total_vol > 0:\n",
        "#                 microprice = (back_1 * lay_vol_1 + lay_1 * back_vol_1) / total_vol\n",
        "#             else:\n",
        "#                 microprice = (back_1 + lay_1) / 2.0\n",
        "\n",
        "#         # Use pre-calculated order book imbalance (like wom)\n",
        "#         wom = to_float(row.get(f'{prefix}ob_imbalance'), 0.5)\n",
        "#         # If not available or invalid, calculate from volumes\n",
        "#         if wom < 0 or wom > 1:\n",
        "#             total_vol = back_vol_1 + lay_vol_1\n",
        "#             if total_vol > 0:\n",
        "#                 wom = back_vol_1 / total_vol\n",
        "#             else:\n",
        "#                 wom = 0.5\n",
        "\n",
        "#         # Use pre-calculated relative spread\n",
        "#         spread = to_float(row.get(f'{prefix}rel_spread'))\n",
        "#         if spread <= 0:\n",
        "#             # Fallback: calculate if not available\n",
        "#             spread = lay_1 - back_1\n",
        "\n",
        "#         # Total matched volume\n",
        "#         total_matched = to_float(row.get(f'{prefix}traded_vol_total'), 0.0)\n",
        "\n",
        "#         return {\n",
        "#             'back_1': back_1,\n",
        "#             'lay_1': lay_1,\n",
        "#             'back_vol_1': back_vol_1,\n",
        "#             'lay_vol_1': lay_vol_1,\n",
        "#             'back_vol_2': back_vol_2,\n",
        "#             'lay_vol_2': lay_vol_2,\n",
        "#             'back_vol_3': back_vol_3,\n",
        "#             'lay_vol_3': lay_vol_3,\n",
        "#             'microprice': microprice,\n",
        "#             'spread': spread,\n",
        "#             'wom': wom,\n",
        "#             'total_matched': total_matched,\n",
        "#             'ltp': ltp,\n",
        "#             'ltv': total_matched,\n",
        "#         }\n",
        "#     except Exception as e:\n",
        "#         return None\n",
        "\n",
        "# print(\"‚úÖ Helper functions loaded\")\n",
        "# print(\"   ‚Ä¢ to_float()\")\n",
        "# print(\"   ‚Ä¢ safe_normalize()\")\n",
        "# print(\"   ‚Ä¢ safe_log_norm()\")\n",
        "# print(\"   ‚Ä¢ get_runner_data() - FIXED for actual data structure\")\n",
        "# print(\"   ‚Ä¢ Maps: back_size‚Üíback_vol, lay_size‚Üílay_vol\")\n",
        "# print(\"   ‚Ä¢ Uses: microprice, ob_imbalance, rel_spread\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 6 - HELPER FUNCTIONS (FINAL CORRECTED VERSION)\n",
        "# ============================================================================\n",
        "#\n",
        "# DROP-IN REPLACEMENT for Cell 6\n",
        "#\n",
        "# COMPLETE FIX - Includes ALL required keys:\n",
        "#\n",
        "# COLUMN NAME FIXES:\n",
        "# - back_size_1/2/3 instead of back_vol_1/2/3\n",
        "# - lay_size_1/2/3 instead of lay_vol_1/2/3\n",
        "# - last_traded_price instead of ltp\n",
        "# - traded_vol_total ‚Üí both 'total_matched' AND 'ltv'\n",
        "# - Uses pre-calculated: microprice, ob_imbalance, rel_spread\n",
        "#\n",
        "# CRITICAL KEYS ADDED:\n",
        "# - 'ltv' ‚Üí Last traded volume (for observations)\n",
        "# - 'is_winner' ‚Üí Race outcome (for settlement)\n",
        "#\n",
        "# ============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîß LOADING HELPER FUNCTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Type-safe helpers\n",
        "def to_float(val, default=0.0):\n",
        "    \"\"\"Convert to float safely.\"\"\"\n",
        "    try:\n",
        "        if val is None or (isinstance(val, float) and np.isnan(val)):\n",
        "            return default\n",
        "        return float(val)\n",
        "    except (ValueError, TypeError):\n",
        "        return default\n",
        "\n",
        "def safe_normalize(val, min_val, max_val):\n",
        "    \"\"\"Normalize value to [0, 1] range.\"\"\"\n",
        "    if val is None or val == 0.0:\n",
        "        return 0.0\n",
        "    val = max(min_val, min(max_val, val))\n",
        "    return (val - min_val) / (max_val - min_val + 1e-8)\n",
        "\n",
        "def safe_log_norm(val, default=0.0):\n",
        "    \"\"\"Log-normalize value.\"\"\"\n",
        "    if val is None or val <= 0:\n",
        "        return default\n",
        "    return np.log1p(val) / 10.0\n",
        "\n",
        "# V41 column extraction (COMPLETE FIX)\n",
        "def get_runner_data(row, runner_idx):\n",
        "    \"\"\"Extract runner data with run[idx] format.\n",
        "\n",
        "    COMPLETE VERSION with all required keys:\n",
        "    - Maps actual column names (back_size, lay_size, etc.)\n",
        "    - Returns ALL keys needed by environment:\n",
        "      * back_1, lay_1 (prices)\n",
        "      * back_vol_1, lay_vol_1, vol_2, vol_3 (volumes)\n",
        "      * ltp, ltv (last traded)\n",
        "      * microprice, wom (derived)\n",
        "      * is_winner (race outcome)\n",
        "      * spread, total_matched (extra)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prefix = f'run[{runner_idx}].'\n",
        "\n",
        "        # Check if runner exists\n",
        "        back_col = f'{prefix}back_price_1'\n",
        "        if back_col not in row.index:\n",
        "            return None\n",
        "\n",
        "        # Extract prices\n",
        "        back_1 = to_float(row.get(f'{prefix}back_price_1'))\n",
        "        lay_1 = to_float(row.get(f'{prefix}lay_price_1'))\n",
        "\n",
        "        if back_1 <= 1.0 or lay_1 <= 1.0:\n",
        "            return None\n",
        "\n",
        "        # Volumes/Sizes - FIXED NAMES (back_size ‚Üí back_vol)\n",
        "        back_vol_1 = to_float(row.get(f'{prefix}back_size_1'), 0.0)\n",
        "        lay_vol_1 = to_float(row.get(f'{prefix}lay_size_1'), 0.0)\n",
        "        back_vol_2 = to_float(row.get(f'{prefix}back_size_2'), 0.0)\n",
        "        lay_vol_2 = to_float(row.get(f'{prefix}lay_size_2'), 0.0)\n",
        "        back_vol_3 = to_float(row.get(f'{prefix}back_size_3'), 0.0)\n",
        "        lay_vol_3 = to_float(row.get(f'{prefix}lay_size_3'), 0.0)\n",
        "\n",
        "        # Last traded price - FIXED NAME\n",
        "        ltp = to_float(row.get(f'{prefix}last_traded_price'), back_1)\n",
        "\n",
        "        # Use pre-calculated microprice if available\n",
        "        microprice = to_float(row.get(f'{prefix}microprice'))\n",
        "        if microprice <= 0:\n",
        "            # Fallback: calculate if not available\n",
        "            total_vol = back_vol_1 + lay_vol_1\n",
        "            if total_vol > 0:\n",
        "                microprice = (back_1 * lay_vol_1 + lay_1 * back_vol_1) / total_vol\n",
        "            else:\n",
        "                microprice = (back_1 + lay_1) / 2.0\n",
        "\n",
        "        # Use pre-calculated order book imbalance (like wom)\n",
        "        wom = to_float(row.get(f'{prefix}ob_imbalance'), 0.5)\n",
        "        # If not available or invalid, calculate from volumes\n",
        "        if wom < 0 or wom > 1:\n",
        "            total_vol = back_vol_1 + lay_vol_1\n",
        "            if total_vol > 0:\n",
        "                wom = back_vol_1 / total_vol\n",
        "            else:\n",
        "                wom = 0.5\n",
        "\n",
        "        # Use pre-calculated relative spread\n",
        "        spread = to_float(row.get(f'{prefix}rel_spread'))\n",
        "        if spread <= 0:\n",
        "            # Fallback: calculate if not available\n",
        "            spread = lay_1 - back_1\n",
        "\n",
        "        # Total matched volume (used for both 'total_matched' and 'ltv')\n",
        "        total_matched = to_float(row.get(f'{prefix}traded_vol_total'), 0.0)\n",
        "\n",
        "        # Winner flag (critical for settlement at race end)\n",
        "        is_winner = to_float(row.get(f'{prefix}is_winner'), 0.0)\n",
        "\n",
        "        # Return ALL required keys\n",
        "        return {\n",
        "            # Prices (required)\n",
        "            'back_1': back_1,\n",
        "            'lay_1': lay_1,\n",
        "\n",
        "            # Volumes - all 3 depth levels (vol_1 required, vol_2/3 optional)\n",
        "            'back_vol_1': back_vol_1,\n",
        "            'lay_vol_1': lay_vol_1,\n",
        "            'back_vol_2': back_vol_2,\n",
        "            'lay_vol_2': lay_vol_2,\n",
        "            'back_vol_3': back_vol_3,\n",
        "            'lay_vol_3': lay_vol_3,\n",
        "\n",
        "            # Derived price features (required)\n",
        "            'microprice': microprice,\n",
        "            'wom': wom,\n",
        "\n",
        "            # Last traded (required)\n",
        "            'ltp': ltp,\n",
        "            'ltv': total_matched,  # ‚Üê CRITICAL: Needed for observations\n",
        "\n",
        "            # Settlement (required)\n",
        "            'is_winner': is_winner,  # ‚Üê CRITICAL: Needed for race outcome\n",
        "\n",
        "            # Extra features (optional but included)\n",
        "            'spread': spread,\n",
        "            'total_matched': total_matched,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Helper functions loaded\")\n",
        "print(\"   ‚Ä¢ to_float()\")\n",
        "print(\"   ‚Ä¢ safe_normalize()\")\n",
        "print(\"   ‚Ä¢ safe_log_norm()\")\n",
        "print(\"   ‚Ä¢ get_runner_data() - COMPLETE FIXED VERSION\")\n",
        "print(\"\")\n",
        "print(\"   Column mappings:\")\n",
        "print(\"   ‚Ä¢ back_size ‚Üí back_vol\")\n",
        "print(\"   ‚Ä¢ lay_size ‚Üí lay_vol\")\n",
        "print(\"   ‚Ä¢ last_traded_price ‚Üí ltp\")\n",
        "print(\"   ‚Ä¢ traded_vol_total ‚Üí ltv & total_matched\")\n",
        "print(\"   ‚Ä¢ ob_imbalance ‚Üí wom\")\n",
        "print(\"   ‚Ä¢ rel_spread ‚Üí spread\")\n",
        "print(\"\")\n",
        "print(\"   ‚úÖ All required keys included:\")\n",
        "print(\"   ‚Ä¢ back_1, lay_1, back_vol_1, lay_vol_1\")\n",
        "print(\"   ‚Ä¢ ltp, ltv, microprice, wom\")\n",
        "print(\"   ‚Ä¢ is_winner (for settlement)\")\n",
        "print(\"   ‚Ä¢ Plus: vol_2/3, spread, total_matched\")"
      ],
      "metadata": {
        "id": "oBiMTEO42fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79a4e0d-4959-4a91-ed0a-0a438ff1316f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîß LOADING HELPER FUNCTIONS\n",
            "================================================================================\n",
            "‚úÖ Helper functions loaded\n",
            "   ‚Ä¢ to_float()\n",
            "   ‚Ä¢ safe_normalize()\n",
            "   ‚Ä¢ safe_log_norm()\n",
            "   ‚Ä¢ get_runner_data() - COMPLETE FIXED VERSION\n",
            "\n",
            "   Column mappings:\n",
            "   ‚Ä¢ back_size ‚Üí back_vol\n",
            "   ‚Ä¢ lay_size ‚Üí lay_vol\n",
            "   ‚Ä¢ last_traded_price ‚Üí ltp\n",
            "   ‚Ä¢ traded_vol_total ‚Üí ltv & total_matched\n",
            "   ‚Ä¢ ob_imbalance ‚Üí wom\n",
            "   ‚Ä¢ rel_spread ‚Üí spread\n",
            "\n",
            "   ‚úÖ All required keys included:\n",
            "   ‚Ä¢ back_1, lay_1, back_vol_1, lay_vol_1\n",
            "   ‚Ä¢ ltp, ltv, microprice, wom\n",
            "   ‚Ä¢ is_winner (for settlement)\n",
            "   ‚Ä¢ Plus: vol_2/3, spread, total_matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MTM/Sharpe Fix Verification ###\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get unwrapped env\n",
        "env = train_env\n",
        "while hasattr(env, 'env'):\n",
        "    env = env.env\n",
        "\n",
        "# Reset and run one episode\n",
        "obs, _ = train_env.reset()\n",
        "print(\"Starting episode...\")\n",
        "\n",
        "for step in range(50):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, info = train_env.step(action)\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}: Total MTM={info.get('total_mtm_reward', 0):.4f}, Total Sharpe={info.get('total_sharpe_reward', 0):.4f}\")\n",
        "\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "print(f\"\\nEpisode completed at step {step}\")\n",
        "print(f\"Final Total MTM: {info.get('total_mtm_reward', 0):.4f}\")\n",
        "print(f\"Final Total Sharpe: {info.get('total_sharpe_reward', 0):.4f}\")\n",
        "\n",
        "if info.get('total_mtm_reward', 0) != 0:\n",
        "    print(\"\\n‚úÖ MTM ACCUMULATION WORKING!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  MTM still zero (may be normal if no positions)\")\n",
        "\n",
        "if info.get('total_sharpe_reward', 0) != 0:\n",
        "    print(\"‚úÖ SHARPE ACCUMULATION WORKING!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Sharpe still zero (may be normal if <10 steps)\")"
      ],
      "metadata": {
        "id": "lI_-LtBqEUSM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "6511c3b2-7c85-444d-8039-4f3fd6bd9ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'back_2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1848298503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Reset and run one episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting episode...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-554991695.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected you to pass keyword argument {key} into reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_reset_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mActType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mObsType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSupportsFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-554991695.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale_market_violations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-554991695.py\u001b[0m in \u001b[0;36m_get_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                     \u001b[0;31m# === LEVEL 2: PRICES & VOLUMES (4 features) ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                     \u001b[0mback_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'back_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m                     \u001b[0mlay_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lay_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                     \u001b[0mback_vol_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_log_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'back_vol_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'back_2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWKR83R9psvr"
      },
      "outputs": [],
      "source": [
        "### CRITICAL TEST - What threshold is actually being used? ###\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CHECKING ACTUAL THRESHOLD IN USE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get the actual curriculum from the environment\n",
        "env = train_env\n",
        "while hasattr(env, 'env'):\n",
        "    env = env.env\n",
        "\n",
        "if hasattr(env, 'curriculum_tracker'):\n",
        "    print(f\"\\nCurriculum tracker values:\")\n",
        "    print(f\"  threshold_start: {env.curriculum_tracker.threshold_start:.3f}\")\n",
        "    print(f\"  threshold_end: {env.curriculum_tracker.threshold_end:.3f}\")\n",
        "    print(f\"  current threshold: {env.curriculum_tracker.get_current_action_threshold():.3f}\")\n",
        "\n",
        "    if env.curriculum_tracker.threshold_start == 0.05:\n",
        "        print(\"\\n‚ùå PROBLEM: Environment using OLD threshold (0.05)!\")\n",
        "        print(\"   You changed Cell 3 but didn't restart runtime!\")\n",
        "        print(\"\\n   FIX: Runtime ‚Üí Restart runtime ‚Üí Rerun all cells\")\n",
        "    elif env.curriculum_tracker.threshold_start == 0.01:\n",
        "        print(\"\\n‚úÖ Environment using NEW threshold (0.01)\")\n",
        "        print(\"   Problem must be elsewhere - run full diagnostic\")\n",
        "\n",
        "# Test if environment can trade with forced signals\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING IF ENVIRONMENT CAN EXECUTE TRADES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "\n",
        "# Force maximum signal strength\n",
        "forced_action = np.ones(25, dtype=np.float32)\n",
        "initial_trades = len(env.trades_this_episode)\n",
        "\n",
        "obs, reward, done, truncated, info = env.step(forced_action)\n",
        "trades_executed = len(env.trades_this_episode) - initial_trades\n",
        "\n",
        "print(f\"\\nForced trade test (all signals = +1.0):\")\n",
        "print(f\"  Trades executed: {trades_executed}\")\n",
        "\n",
        "if trades_executed == 0:\n",
        "    print(\"\\n  ‚ùå Environment CANNOT execute trades!\")\n",
        "    print(\"     Deeper blocking bug - run full diagnostic\")\n",
        "else:\n",
        "    print(f\"\\n  ‚úÖ Environment CAN trade! ({trades_executed} trades)\")\n",
        "\n",
        "    # Now test with SAC\n",
        "    obs, _ = env.reset()\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "    threshold = env.curriculum_tracker.get_current_action_threshold()\n",
        "\n",
        "    print(f\"\\nSAC signal test:\")\n",
        "    print(f\"  Threshold: {threshold:.3f}\")\n",
        "    print(f\"  SAC signals: min={action[:24].min():+.4f}, max={action[:24].max():+.4f}\")\n",
        "    print(f\"  Signals >= threshold: {(np.abs(action[:24]) >= threshold).sum()}/24\")\n",
        "\n",
        "    if (np.abs(action[:24]) >= threshold).sum() == 0:\n",
        "        print(\"\\n  ‚ùå Even at 0.01, SAC signals too weak!\")\n",
        "        print(\"     Lower threshold to 0.005\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB1vFGhX8QSd"
      },
      "outputs": [],
      "source": [
        "### V42 Green-Up Verification ###\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ V42 GREEN-UP STRATEGY VERIFICATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get unwrapped environment\n",
        "env = train_env\n",
        "while hasattr(env, 'env'):\n",
        "    env = env.env\n",
        "\n",
        "# Check that green-up methods exist\n",
        "print(\"\\n‚úì Checking V42 methods:\")\n",
        "print(f\"  _check_in_play_transition: {hasattr(env, '_check_in_play_transition')}\")\n",
        "print(f\"  _calculate_green_up_pnl: {hasattr(env, '_calculate_green_up_pnl')}\")\n",
        "\n",
        "# Check observation space (should still be 323)\n",
        "print(f\"\\n‚úì Observation space: {env.observation_space.shape}\")\n",
        "print(f\"  Expected: (323,) - {'‚úÖ CORRECT' if env.observation_space.shape == (323,) else '‚ùå ERROR'}\")\n",
        "\n",
        "# Check action space (should still be 25)\n",
        "print(f\"\\n‚úì Action space: {env.action_space.shape}\")\n",
        "print(f\"  Expected: (25,) - {'‚úÖ CORRECT' if env.action_space.shape == (25,) else '‚ùå ERROR'}\")\n",
        "\n",
        "# Check MTM/Sharpe accumulators\n",
        "print(f\"\\n‚úì V41 features maintained:\")\n",
        "print(f\"  total_mtm_reward: {hasattr(env, 'total_mtm_reward')}\")\n",
        "print(f\"  total_sharpe_reward: {hasattr(env, 'total_sharpe_reward')}\")\n",
        "print(f\"  pnl_history: {hasattr(env, 'pnl_history')}\")\n",
        "print(f\"  price_history: {hasattr(env, 'price_history')}\")\n",
        "\n",
        "# Run a quick episode to test green-up\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING GREEN-UP MECHANISM\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "episode_steps = 0\n",
        "had_trades = False\n",
        "\n",
        "for step in range(500):  # Enough steps to reach in-play\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    episode_steps += 1\n",
        "\n",
        "    if info.get('trades_executed', 0) > 0:\n",
        "        had_trades = True\n",
        "\n",
        "    if done:\n",
        "        print(f\"\\n‚úì Episode completed (Green-up executed):\")\n",
        "        print(f\"  Steps to in-play: {episode_steps}\")\n",
        "        print(f\"  Trades executed: {len(env.trades_this_episode)}\")\n",
        "        print(f\"  Final balance: ${env.balance:.2f}\")\n",
        "        print(f\"  Final P&L: ${info['final_pnl']:.2f}\")\n",
        "        print(f\"  Positions at end: {len(env.positions)} (should be 0)\")\n",
        "\n",
        "        if len(env.positions) == 0:\n",
        "            print(\"\\n‚úÖ GREEN-UP WORKING: All positions closed!\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è  WARNING: Positions still open after green-up\")\n",
        "\n",
        "        break\n",
        "\n",
        "if not done:\n",
        "    print(f\"\\n‚ö†Ô∏è  Episode didn't complete in {step} steps\")\n",
        "    print(\"  (May need more steps to reach in-play)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ V42 VERIFICATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nAll V41 features maintained: ‚úÖ\")\n",
        "print(\"Green-up strategy implemented: ‚úÖ\")\n",
        "print(\"Ready for training: ‚úÖ\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDE_PwaA3scv"
      },
      "outputs": [],
      "source": [
        "  ### PRE-TRAINING VERIFICATION - Run ONE Complete Episode ###\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üî¨ PRE-TRAINING VERIFICATION: Running ONE Complete Episode\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nThis will run exactly one episode to verify:\")\n",
        "print(\"  ‚Ä¢ Trades execute during actual training loop\")\n",
        "print(\"  ‚Ä¢ Metrics are collected correctly\")\n",
        "print(\"  ‚Ä¢ Rewards are calculated properly\")\n",
        "print(\"  ‚Ä¢ CSV logging works\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get the unwrapped environment for inspection\n",
        "test_env = train_env\n",
        "base_env = test_env\n",
        "while hasattr(base_env, 'env'):\n",
        "    base_env = base_env.env\n",
        "\n",
        "print(f\"\\n1Ô∏è‚É£ Environment Setup:\")\n",
        "print(f\"   Type: {type(base_env).__name__}\")\n",
        "print(f\"   Wrapper chain: {type(train_env).__name__} (should include Monitor)\")\n",
        "\n",
        "# Reset and run one episode\n",
        "print(f\"\\n2Ô∏è‚É£ Running one complete episode...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "obs, info = train_env.reset()\n",
        "done = False\n",
        "truncated = False\n",
        "step_count = 0\n",
        "total_reward = 0.0\n",
        "trades_per_step = []\n",
        "\n",
        "# Track rewards\n",
        "step_rewards = []\n",
        "mtm_rewards = []\n",
        "sharpe_rewards = []\n",
        "\n",
        "while not done and not truncated and step_count < 1000:\n",
        "    # Get action from model\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "\n",
        "    # Execute step\n",
        "    obs, reward, done, truncated, info = train_env.step(action)\n",
        "\n",
        "    step_count += 1\n",
        "    total_reward += reward\n",
        "    step_rewards.append(reward)\n",
        "\n",
        "    # Track trades this step\n",
        "    current_trades = len(base_env.trades_this_episode)\n",
        "    trades_per_step.append(current_trades)\n",
        "\n",
        "    # Print progress every 100 steps\n",
        "    if step_count % 100 == 0:\n",
        "        print(f\"   Step {step_count}: {current_trades} trades so far, reward={reward:+.2f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Episode completed!\")\n",
        "print(f\"   Total steps: {step_count}\")\n",
        "print(f\"   Episode ended: done={done}, truncated={truncated}\")\n",
        "\n",
        "# Get final metrics\n",
        "final_trades = len(base_env.trades_this_episode)\n",
        "final_balance = base_env.balance\n",
        "final_pnl = final_balance - base_env.initial_balance\n",
        "\n",
        "print(f\"\\n3Ô∏è‚É£ Episode Metrics:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"   Trades executed: {final_trades}\")\n",
        "print(f\"   Final balance: ${final_balance:.2f}\")\n",
        "print(f\"   Initial balance: ${base_env.initial_balance:.2f}\")\n",
        "print(f\"   Realized P&L: ${final_pnl:+.2f}\")\n",
        "print(f\"   Total reward: {total_reward:+.2f}\")\n",
        "print(f\"   Avg reward/step: {total_reward/step_count:+.4f}\")\n",
        "\n",
        "# Check info dict\n",
        "print(f\"\\n4Ô∏è‚É£ Info Dictionary Contents:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"   Keys: {list(info.keys())}\")\n",
        "\n",
        "if 'episode' in info:\n",
        "    print(f\"   Episode info keys: {list(info['episode'].keys())}\")\n",
        "    print(f\"\\n   Episode info values:\")\n",
        "    for key, value in info['episode'].items():\n",
        "        print(f\"      {key}: {value}\")\n",
        "\n",
        "# Check no-trade penalty\n",
        "if 'no_trade_streak' in info or ('episode' in info and 'no_trade_streak' in info['episode']):\n",
        "    if 'episode' in info:\n",
        "        streak = info['episode'].get('no_trade_streak', 0)\n",
        "        penalty = info['episode'].get('no_trade_penalty', 0.0)\n",
        "    else:\n",
        "        streak = info.get('no_trade_streak', 0)\n",
        "        penalty = info.get('no_trade_penalty', 0.0)\n",
        "\n",
        "    print(f\"\\n5Ô∏è‚É£ No-Trade Penalty System:\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"   No-trade streak: {streak}\")\n",
        "    print(f\"   Penalty applied: {penalty:.2f}\")\n",
        "    print(f\"   Had trades: {final_trades > 0}\")\n",
        "\n",
        "    if final_trades > 0 and streak > 0:\n",
        "        print(f\"   ‚ö†Ô∏è  WARNING: Had trades but streak > 0!\")\n",
        "    elif final_trades == 0 and streak == 0:\n",
        "        print(f\"   ‚ö†Ô∏è  WARNING: No trades but streak = 0!\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Penalty system working correctly\")\n",
        "\n",
        "# Analyze trade distribution\n",
        "if final_trades > 0:\n",
        "    print(f\"\\n6Ô∏è‚É£ Trade Analysis:\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    trade_steps = [i for i in range(len(trades_per_step)) if i == 0 or trades_per_step[i] > trades_per_step[i-1]]\n",
        "\n",
        "    print(f\"   Total trades: {final_trades}\")\n",
        "    print(f\"   Steps with trades: {len(trade_steps)}\")\n",
        "    print(f\"   Trade rate: {len(trade_steps)/step_count*100:.1f}%\")\n",
        "\n",
        "    # Sample some trades\n",
        "    if len(base_env.trades_this_episode) > 0:\n",
        "        print(f\"\\n   First 3 trades:\")\n",
        "        for i, trade in enumerate(base_env.trades_this_episode[:3]):\n",
        "            print(f\"      Trade {i+1}: {trade['side']} runner {trade['runner']} @ {trade['price']:.2f}, stake=${trade['stake']:.2f}\")\n",
        "\n",
        "        if len(base_env.trades_this_episode) > 3:\n",
        "            print(f\"   ... and {len(base_env.trades_this_episode) - 3} more\")\n",
        "\n",
        "# Check what would be saved to CSV\n",
        "print(f\"\\n7Ô∏è‚É£ What Would Be Saved to CSV:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Simulate what TrainingMetricsCallback would save\n",
        "if 'episode' in info:\n",
        "    episode_info = info['episode']\n",
        "    csv_data = {\n",
        "        'Episode': 1,\n",
        "        'Step': step_count,\n",
        "        'Balance': final_balance,\n",
        "        'Num_Trades': episode_info.get('num_trades', final_trades),\n",
        "        'Realized_PnL': final_pnl,\n",
        "        'No_Trade_Streak': episode_info.get('no_trade_streak', 0),\n",
        "        'No_Trade_Penalty': episode_info.get('no_trade_penalty', 0.0),\n",
        "        'Had_Trades': episode_info.get('had_trades', final_trades > 0),\n",
        "        'Max_Drawdown': (base_env.peak_balance - final_balance) / base_env.peak_balance if base_env.peak_balance > 0 else 0.0,\n",
        "        'MTM_Reward': info.get('total_mtm_reward', 0.0),\n",
        "        'Sharpe_Reward': info.get('total_sharpe_reward', 0.0)\n",
        "    }\n",
        "else:\n",
        "    csv_data = {\n",
        "        'Episode': 1,\n",
        "        'Step': step_count,\n",
        "        'Balance': final_balance,\n",
        "        'Num_Trades': final_trades,\n",
        "        'Realized_PnL': final_pnl,\n",
        "        'No_Trade_Streak': info.get('no_trade_streak', 0),\n",
        "        'No_Trade_Penalty': info.get('no_trade_penalty', 0.0),\n",
        "        'Had_Trades': final_trades > 0,\n",
        "        'Max_Drawdown': (base_env.peak_balance - final_balance) / base_env.peak_balance if base_env.peak_balance > 0 else 0.0,\n",
        "        'MTM_Reward': info.get('total_mtm_reward', 0.0),\n",
        "        'Sharpe_Reward': info.get('total_sharpe_reward', 0.0)\n",
        "    }\n",
        "\n",
        "print(\"\\n   CSV row that would be saved:\")\n",
        "for key, value in csv_data.items():\n",
        "    print(f\"      {key}: {value}\")\n",
        "\n",
        "# Final verdict\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ VERIFICATION RESULT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "issues = []\n",
        "\n",
        "if final_trades == 0:\n",
        "    issues.append(\"‚ùå NO TRADES EXECUTED!\")\n",
        "    print(\"\\n‚ùå CRITICAL ISSUE: No trades executed!\")\n",
        "    print(\"   DO NOT proceed to full training\")\n",
        "    print(\"   Run the COMPREHENSIVE_DIAGNOSTIC.py to find the blocking point\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ SUCCESS: {final_trades} trades executed!\")\n",
        "\n",
        "if final_balance == base_env.initial_balance and final_trades > 0:\n",
        "    issues.append(\"‚ö†Ô∏è  Balance unchanged despite trades\")\n",
        "    print(\"‚ö†Ô∏è  WARNING: Balance unchanged despite trades\")\n",
        "\n",
        "if abs(total_reward) < 0.01:\n",
        "    issues.append(\"‚ö†Ô∏è  Total reward near zero\")\n",
        "    print(\"‚ö†Ô∏è  WARNING: Total reward very small\")\n",
        "\n",
        "if final_trades == 0 and csv_data['No_Trade_Streak'] == 0:\n",
        "    issues.append(\"‚ö†Ô∏è  No-trade penalty not working\")\n",
        "    print(\"‚ö†Ô∏è  WARNING: No-trade penalty system not working\")\n",
        "\n",
        "if len(issues) == 0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üöÄ ALL CHECKS PASSED - READY FOR FULL TRAINING!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nExpected results in full training:\")\n",
        "    print(f\"  ‚Ä¢ Episodes will execute {final_trades} ¬± 5 trades\")\n",
        "    print(f\"  ‚Ä¢ Balance will vary around ${final_balance:.0f}\")\n",
        "    print(f\"  ‚Ä¢ Rewards will average around {total_reward:.0f}\")\n",
        "    print(\"\\nYou can proceed to Cell 6 (Training) with confidence!\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  ISSUES DETECTED - DO NOT START FULL TRAINING YET\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nIssues found:\")\n",
        "    for issue in issues:\n",
        "        print(f\"  {issue}\")\n",
        "    print(\"\\nResolve these issues before starting full training.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61eej9yLiwGU"
      },
      "outputs": [],
      "source": [
        "### DATA STRUCTURE DIAGNOSTIC ###\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Load one race file\n",
        "race_file = random.choice(train_files)\n",
        "df = pd.read_parquet(race_file)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATA STRUCTURE DIAGNOSTIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n1Ô∏è‚É£ File: {race_file.split('/')[-1]}\")\n",
        "print(f\"   Shape: {df.shape}\")\n",
        "print(f\"   Columns: {len(df.columns)}\")\n",
        "\n",
        "print(f\"\\n2Ô∏è‚É£ First row columns (first 50):\")\n",
        "for i, col in enumerate(df.columns[:50]):\n",
        "    print(f\"   {i}: {col}\")\n",
        "\n",
        "print(f\"\\n3Ô∏è‚É£ Looking for runner data...\")\n",
        "\n",
        "# Check for runner columns\n",
        "runner_cols = [col for col in df.columns if 'runner' in col.lower()]\n",
        "print(f\"   Found {len(runner_cols)} columns with 'runner' in name\")\n",
        "\n",
        "if len(runner_cols) > 0:\n",
        "    print(f\"\\n   First 10 runner columns:\")\n",
        "    for col in runner_cols[:10]:\n",
        "        print(f\"      {col}\")\n",
        "else:\n",
        "    print(f\"   ‚ùå NO columns with 'runner' found!\")\n",
        "\n",
        "# Check specific columns we're looking for\n",
        "print(f\"\\n4Ô∏è‚É£ Checking for expected columns:\")\n",
        "expected = [\n",
        "    'runner_0_back_1',\n",
        "    'runner_0_lay_1',\n",
        "    'runner_0_back_vol_1',\n",
        "    'runner_count'\n",
        "]\n",
        "\n",
        "for col in expected:\n",
        "    exists = col in df.columns\n",
        "    symbol = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "    print(f\"   {symbol} {col}: {exists}\")\n",
        "\n",
        "# Check first row values\n",
        "print(f\"\\n5Ô∏è‚É£ First row sample data:\")\n",
        "row = df.iloc[0]\n",
        "\n",
        "if 'runner_count' in df.columns:\n",
        "    print(f\"   runner_count: {row['runner_count']}\")\n",
        "\n",
        "# Try to get runner 0 data\n",
        "prefix = 'runner_0_'\n",
        "for suffix in ['back_1', 'lay_1', 'back_vol_1', 'lay_vol_1']:\n",
        "    col_name = f'{prefix}{suffix}'\n",
        "    if col_name in df.columns:\n",
        "        print(f\"   ‚úÖ {col_name}: {row[col_name]}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {col_name}: NOT FOUND (using default)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "# ```\n",
        "\n",
        "# ---\n",
        "\n",
        "# ## üéØ **Expected Results**\n",
        "\n",
        "# ### **If data structure is correct:**\n",
        "# ```\n",
        "# ‚úÖ runner_0_back_1: True\n",
        "# ‚úÖ runner_0_lay_1: True\n",
        "#    runner_0_back_1: 2.58\n",
        "#    runner_0_lay_1: 2.60\n",
        "# ```\n",
        "\n",
        "# ### **If data structure is wrong (LIKELY):**\n",
        "# ```\n",
        "# ‚ùå runner_0_back_1: False\n",
        "# ‚ùå runner_0_lay_1: False\n",
        "#    runner_0_back_1: NOT FOUND (using default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57Ma-WhPjFnC"
      },
      "outputs": [],
      "source": [
        "### IMMEDIATE DIAGNOSTIC - Run this NOW to find blocking point ###\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üî¨ EMERGENCY DIAGNOSTIC - Finding Why 0 Trades\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get the unwrapped environment\n",
        "test_env = train_env\n",
        "while hasattr(test_env, 'env'):\n",
        "    test_env = test_env.env\n",
        "\n",
        "print(f\"\\nEnvironment type: {type(test_env).__name__}\")\n",
        "\n",
        "# Test 1: Check data structure\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"1Ô∏è‚É£ DATA STRUCTURE CHECK\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    # Load a random race\n",
        "    race_file = random.choice(train_files)\n",
        "    df = pd.read_parquet(race_file)\n",
        "    row = df.iloc[0]\n",
        "\n",
        "    print(f\"\\nRace file: {race_file.split('/')[-1]}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"runner_count: {row.get('runner_count', 'MISSING!')}\")\n",
        "\n",
        "    # Check column format\n",
        "    print(\"\\nüìã Checking column names:\")\n",
        "\n",
        "    runner_cols = [c for c in df.columns if 'run[' in c]\n",
        "    if len(runner_cols) > 0:\n",
        "        print(f\"  ‚úÖ Found {len(runner_cols)} columns with 'run[' format\")\n",
        "        print(f\"\\n  First 10 run[ columns:\")\n",
        "        for col in runner_cols[:10]:\n",
        "            print(f\"    {col}: {row[col]}\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå NO columns with 'run[' format found!\")\n",
        "\n",
        "        # Check for alternative formats\n",
        "        alt_cols = [c for c in df.columns if 'runner' in c.lower() or 'back' in c.lower()]\n",
        "        print(f\"\\n  Found {len(alt_cols)} alternative columns:\")\n",
        "        for col in alt_cols[:10]:\n",
        "            print(f\"    {col}\")\n",
        "\n",
        "    # Test get_runner_data on this row\n",
        "    print(\"\\nüìä Testing get_runner_data() on row 0:\")\n",
        "    for runner_idx in range(min(3, int(row.get('runner_count', 0)))):\n",
        "        runner_data = get_runner_data(row, runner_idx)\n",
        "        if runner_data:\n",
        "            print(f\"  ‚úÖ Runner {runner_idx}: back={runner_data['back_1']:.2f}, lay={runner_data['lay_1']:.2f}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå Runner {runner_idx}: FAILED\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# Test 2: Reset environment and check\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"2Ô∏è‚É£ ENVIRONMENT RESET CHECK\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    obs, info = test_env.reset()\n",
        "\n",
        "    print(f\"\\nAfter reset:\")\n",
        "    print(f\"  runner_count: {test_env.runner_count}\")\n",
        "    print(f\"  balance: ${test_env.balance:.2f}\")\n",
        "    print(f\"  data shape: {test_env.current_race_df.shape}\")\n",
        "    print(f\"  step_idx: {test_env.step_idx}\")\n",
        "\n",
        "    # Test runner data extraction\n",
        "    print(f\"\\nüìä Testing runner data extraction:\")\n",
        "    current_row = test_env.current_race_df.iloc[0]\n",
        "\n",
        "    valid_runners = 0\n",
        "    for runner_idx in range(min(5, test_env.runner_count)):\n",
        "        runner_data = get_runner_data(current_row, runner_idx)\n",
        "        if runner_data:\n",
        "            valid_runners += 1\n",
        "            print(f\"  ‚úÖ Runner {runner_idx}: back={runner_data['back_1']:.2f}, lay={runner_data['lay_1']:.2f}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå Runner {runner_idx}: get_runner_data() returned None\")\n",
        "\n",
        "    if valid_runners == 0:\n",
        "        print(f\"\\n‚ùå BLOCKING ISSUE: ALL runners return None!\")\n",
        "        print(f\"   This is why 0 trades - no valid data!\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ Data extraction working ({valid_runners}/{min(5, test_env.runner_count)} valid)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Test 3: Try to execute one step\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"3Ô∏è‚É£ SINGLE STEP EXECUTION TEST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    obs, _ = test_env.reset()\n",
        "\n",
        "    # Get curriculum values\n",
        "    if hasattr(test_env, 'curriculum_tracker') and test_env.curriculum_tracker:\n",
        "        threshold = test_env.curriculum_tracker.get_current_action_threshold()\n",
        "        min_liability = test_env.curriculum_tracker.get_current_min_liability()\n",
        "    else:\n",
        "        threshold = 0.01\n",
        "        min_liability = 0.05\n",
        "\n",
        "    print(f\"\\nCurriculum settings:\")\n",
        "    print(f\"  action_threshold: {threshold:.4f}\")\n",
        "    print(f\"  min_liability: ${min_liability:.2f}\")\n",
        "\n",
        "    # Create a forced strong action\n",
        "    forced_action = np.ones(25, dtype=np.float32)  # All signals = +1.0\n",
        "    print(f\"\\nForced action: all signals = +1.0, allocation = +1.0\")\n",
        "\n",
        "    # Count blocking before step\n",
        "    print(f\"\\nBefore step:\")\n",
        "    print(f\"  trades_this_episode: {len(test_env.trades_this_episode)}\")\n",
        "\n",
        "    # Execute step\n",
        "    obs, reward, done, truncated, info = test_env.step(forced_action)\n",
        "\n",
        "    trades_executed = len(test_env.trades_this_episode)\n",
        "\n",
        "    print(f\"\\nAfter step:\")\n",
        "    print(f\"  trades_executed: {trades_executed}\")\n",
        "    print(f\"  balance: ${test_env.balance:.2f}\")\n",
        "    print(f\"  reward: {reward:.2f}\")\n",
        "\n",
        "    if trades_executed == 0:\n",
        "        print(f\"\\n‚ùå CRITICAL: Even with forced max signals, NO trades!\")\n",
        "        print(f\"   This proves there's a blocking condition\")\n",
        "\n",
        "        # Manually check what would block\n",
        "        current_row = test_env.current_race_df.iloc[0]\n",
        "        current_exposure = test_env._get_total_exposure_with_liability()\n",
        "        unreserved_capital = max(0.0, test_env.balance - current_exposure)\n",
        "        available_capital = unreserved_capital * (1.0 - RESERVE_RATIO)\n",
        "        trade_budget = available_capital * 1.0 * MAX_EXPOSURE_MULTIPLIER\n",
        "\n",
        "        print(f\"\\n   Capital calculation:\")\n",
        "        print(f\"     balance: ${test_env.balance:.2f}\")\n",
        "        print(f\"     exposure: ${current_exposure:.2f}\")\n",
        "        print(f\"     unreserved: ${unreserved_capital:.2f}\")\n",
        "        print(f\"     reserve_ratio: {RESERVE_RATIO*100:.0f}%\")\n",
        "        print(f\"     available: ${available_capital:.2f}\")\n",
        "        print(f\"     trade_budget: ${trade_budget:.2f}\")\n",
        "\n",
        "        if trade_budget < min_liability:\n",
        "            print(f\"\\n   ‚ùå FOUND IT: Budget ${trade_budget:.2f} < min_liability ${min_liability:.2f}\")\n",
        "            print(f\"      Even with max allocation, can't afford minimum trade!\")\n",
        "\n",
        "        # Check individual runners\n",
        "        print(f\"\\n   Checking each runner:\")\n",
        "        blocked_data = 0\n",
        "        blocked_price = 0\n",
        "        blocked_budget = 0\n",
        "\n",
        "        for runner_idx in range(min(test_env.runner_count, 5)):\n",
        "            runner_data = get_runner_data(current_row, runner_idx)\n",
        "\n",
        "            if runner_data is None:\n",
        "                blocked_data += 1\n",
        "                print(f\"     Runner {runner_idx}: ‚ùå data=None\")\n",
        "            else:\n",
        "                price = runner_data['back_1']\n",
        "                if price < 1.01 or price > 1000:\n",
        "                    blocked_price += 1\n",
        "                    print(f\"     Runner {runner_idx}: ‚ùå price={price:.2f} (out of range)\")\n",
        "                else:\n",
        "                    signal_strength = 1.0  # Max signal\n",
        "                    runner_budget = trade_budget * signal_strength\n",
        "\n",
        "                    if runner_budget < min_liability:\n",
        "                        blocked_budget += 1\n",
        "                        print(f\"     Runner {runner_idx}: ‚ùå budget=${runner_budget:.2f} < ${min_liability:.2f}\")\n",
        "                    else:\n",
        "                        print(f\"     Runner {runner_idx}: ‚úÖ Should trade! (but didn't)\")\n",
        "\n",
        "        print(f\"\\n   SUMMARY:\")\n",
        "        print(f\"     Blocked by data: {blocked_data}\")\n",
        "        print(f\"     Blocked by price: {blocked_price}\")\n",
        "        print(f\"     Blocked by budget: {blocked_budget}\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ SUCCESS: {trades_executed} trades executed!\")\n",
        "        print(f\"   System CAN trade - problem is with SAC signals\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Test 4: Check SAC action values\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"4Ô∏è‚É£ SAC ACTION VALUES CHECK\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    obs, _ = test_env.reset()\n",
        "\n",
        "    # Get SAC action\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "\n",
        "    runner_signals = action[:24]\n",
        "    allocation = action[24]\n",
        "\n",
        "    print(f\"\\nSAC action analysis:\")\n",
        "    print(f\"  signals: min={runner_signals.min():+.4f}, max={runner_signals.max():+.4f}\")\n",
        "    print(f\"  signals mean: {np.mean(np.abs(runner_signals)):.4f}\")\n",
        "    print(f\"  allocation: {allocation:+.4f}\")\n",
        "\n",
        "    # Check against threshold\n",
        "    if hasattr(test_env, 'curriculum_tracker') and test_env.curriculum_tracker:\n",
        "        threshold = test_env.curriculum_tracker.get_current_action_threshold()\n",
        "    else:\n",
        "        threshold = 0.01\n",
        "\n",
        "    strong_signals = (np.abs(runner_signals) >= threshold).sum()\n",
        "    print(f\"\\n  Signals >= threshold {threshold:.4f}: {strong_signals}/24\")\n",
        "\n",
        "    if strong_signals == 0:\n",
        "        print(f\"\\n  ‚ùå ALL SAC signals too weak!\")\n",
        "        print(f\"     Even at threshold {threshold:.4f}, nothing passes\")\n",
        "        print(f\"     This would cause 0 trades\")\n",
        "    else:\n",
        "        print(f\"\\n  ‚úÖ {strong_signals} signals pass threshold\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DIAGNOSTIC COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüéØ MOST LIKELY ISSUE:\")\n",
        "print(\"   Check the output above to see which test failed!\")\n",
        "print(\"\\n   If Test 1 shows 'NO columns with run[ format':\")\n",
        "print(\"     ‚Üí Column names don't match - need to update get_runner_data()\")\n",
        "print(\"\\n   If Test 2 shows 'ALL runners return None':\")\n",
        "print(\"     ‚Üí Data extraction broken - check column format\")\n",
        "print(\"\\n   If Test 3 shows 'Budget < min_liability':\")\n",
        "print(\"     ‚Üí Lower INITIAL_MIN_LIABILITY or increase capital\")\n",
        "print(\"\\n   If Test 3 shows 'ALL SAC signals too weak':\")\n",
        "print(\"     ‚Üí Lower INITIAL_ACTION_THRESHOLD\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### üî¨ DIAGNOSTIC CELL - V41 BUG DETECTION ###\n",
        "# Drop this into your notebook to identify all critical bugs\n",
        "# Run AFTER Cell 5 (environment setup) but BEFORE training\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üî¨ V41 COMPREHENSIVE BUG DIAGNOSTIC\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nThis will test:\")\n",
        "print(\"  1. MTM Reward Calculation\")\n",
        "print(\"  2. Sharpe Reward Calculation\")\n",
        "print(\"  3. Breakeven/Balance Reset Bug\")\n",
        "print(\"  4. Validation Callback Issues\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# TEST 1: MTM REWARD CALCULATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST 1: MTM REWARD CALCULATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get the actual environment\n",
        "test_env = train_env\n",
        "while hasattr(test_env, 'env'):\n",
        "    test_env = test_env.env\n",
        "\n",
        "# Reset and take a few steps\n",
        "obs, info = test_env.reset()\n",
        "initial_balance = test_env.balance\n",
        "\n",
        "print(f\"\\nInitial balance: ${initial_balance:.2f}\")\n",
        "print(f\"Testing 10 steps to see if MTM rewards are calculated...\\n\")\n",
        "\n",
        "mtm_rewards = []\n",
        "balances = []\n",
        "step_count = 0\n",
        "\n",
        "for i in range(10):\n",
        "    # Generate a random action\n",
        "    action = np.random.randn(25).astype(np.float32)\n",
        "\n",
        "    # Store balance before step\n",
        "    balance_before = test_env.balance\n",
        "\n",
        "    # Take step\n",
        "    obs, reward, done, truncated, info = test_env.step(action)\n",
        "    step_count += 1\n",
        "\n",
        "    # Check if environment has MTM reward attribute/calculation\n",
        "    mtm_reward = 0.0\n",
        "\n",
        "    # Try to find MTM reward in different places\n",
        "    if hasattr(test_env, 'mtm_reward'):\n",
        "        mtm_reward = test_env.mtm_reward\n",
        "    elif hasattr(test_env, 'last_mtm_reward'):\n",
        "        mtm_reward = test_env.last_mtm_reward\n",
        "    elif 'mtm_reward' in info:\n",
        "        mtm_reward = info['mtm_reward']\n",
        "\n",
        "    mtm_rewards.append(mtm_reward)\n",
        "    balances.append(test_env.balance)\n",
        "\n",
        "    balance_change = test_env.balance - balance_before\n",
        "\n",
        "    print(f\"Step {i+1}: Balance=${test_env.balance:8.2f} (Œî${balance_change:+8.2f}) | \"\n",
        "          f\"Reward={reward:+8.4f} | MTM={mtm_reward:+8.4f}\")\n",
        "\n",
        "    if done or truncated:\n",
        "        print(f\"  Episode ended at step {i+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Total steps: {step_count}\")\n",
        "print(f\"  Non-zero MTM rewards: {sum(1 for r in mtm_rewards if abs(r) > 1e-6)}/{len(mtm_rewards)}\")\n",
        "print(f\"  MTM reward range: [{min(mtm_rewards):.4f}, {max(mtm_rewards):.4f}]\")\n",
        "print(f\"  Balance changed: {abs(test_env.balance - initial_balance) > 0.01}\")\n",
        "\n",
        "# Diagnosis\n",
        "if sum(1 for r in mtm_rewards if abs(r) > 1e-6) == 0:\n",
        "    print(f\"\\n‚ùå BUG DETECTED: MTM rewards are ALL ZERO!\")\n",
        "    print(f\"   Expected: Non-zero values reflecting position value changes\")\n",
        "    print(f\"   Actual: All zeros\")\n",
        "    print(f\"\\n   üîç Check in MarketMakingEnv.step():\")\n",
        "    print(f\"      - Is mtm_reward being calculated?\")\n",
        "    print(f\"      - Is it being added to the reward?\")\n",
        "    print(f\"      - Search for 'mtm' or 'mark_to_market' in the code\")\n",
        "elif sum(1 for r in mtm_rewards if abs(r) > 1e-6) < len(mtm_rewards) * 0.5:\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: MTM rewards mostly zero ({sum(1 for r in mtm_rewards if abs(r) > 1e-6)}/{len(mtm_rewards)} non-zero)\")\n",
        "    print(f\"   This might be expected if no positions are open\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ MTM rewards appear to be working!\")\n",
        "    print(f\"   {sum(1 for r in mtm_rewards if abs(r) > 1e-6)}/{len(mtm_rewards)} steps had non-zero MTM rewards\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEST 2: SHARPE REWARD CALCULATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST 2: SHARPE REWARD CALCULATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Reset environment\n",
        "obs, info = test_env.reset()\n",
        "\n",
        "print(f\"\\nTesting Sharpe reward calculation over full episode...\\n\")\n",
        "\n",
        "sharpe_rewards = []\n",
        "episode_returns = []\n",
        "step_count = 0\n",
        "\n",
        "for i in range(1000):  # Max 1000 steps\n",
        "    action = np.random.randn(25).astype(np.float32)\n",
        "    obs, reward, done, truncated, info = test_env.step(action)\n",
        "    step_count += 1\n",
        "\n",
        "    # Try to find Sharpe reward\n",
        "    sharpe_reward = 0.0\n",
        "    if hasattr(test_env, 'sharpe_reward'):\n",
        "        sharpe_reward = test_env.sharpe_reward\n",
        "    elif hasattr(test_env, 'last_sharpe_reward'):\n",
        "        sharpe_reward = test_env.last_sharpe_reward\n",
        "    elif 'sharpe_reward' in info:\n",
        "        sharpe_reward = info['sharpe_reward']\n",
        "\n",
        "    sharpe_rewards.append(sharpe_reward)\n",
        "    episode_returns.append(reward)\n",
        "\n",
        "    if done or truncated:\n",
        "        break\n",
        "\n",
        "print(f\"Results:\")\n",
        "print(f\"  Episode steps: {step_count}\")\n",
        "print(f\"  Non-zero Sharpe rewards: {sum(1 for r in sharpe_rewards if abs(r) > 1e-6)}/{len(sharpe_rewards)}\")\n",
        "print(f\"  Sharpe reward range: [{min(sharpe_rewards):.6f}, {max(sharpe_rewards):.6f}]\")\n",
        "\n",
        "# Calculate what Sharpe SHOULD be\n",
        "if len(episode_returns) > 10:\n",
        "    expected_sharpe = np.mean(episode_returns) / (np.std(episode_returns) + 1e-8)\n",
        "    print(f\"  Expected Sharpe ratio: {expected_sharpe:.6f}\")\n",
        "else:\n",
        "    expected_sharpe = None\n",
        "    print(f\"  (Not enough returns to calculate expected Sharpe)\")\n",
        "\n",
        "# Diagnosis\n",
        "if sum(1 for r in sharpe_rewards if abs(r) > 1e-6) == 0:\n",
        "    print(f\"\\n‚ùå BUG DETECTED: Sharpe rewards are ALL ZERO!\")\n",
        "    print(f\"   Expected: Non-zero values based on return distribution\")\n",
        "    if expected_sharpe:\n",
        "        print(f\"   Expected Sharpe: ~{expected_sharpe:.6f}\")\n",
        "    print(f\"   Actual: All zeros\")\n",
        "    print(f\"\\n   üîç Check in MarketMakingEnv.step():\")\n",
        "    print(f\"      - Is sharpe_reward being calculated?\")\n",
        "    print(f\"      - Is it using episode returns history?\")\n",
        "    print(f\"      - Search for 'sharpe' in the code\")\n",
        "elif sum(1 for r in sharpe_rewards if abs(r) > 1e-6) < 10:\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: Very few non-zero Sharpe rewards\")\n",
        "    print(f\"   Sharpe calculation might require more data\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Sharpe rewards appear to be working!\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEST 3: BREAKEVEN / BALANCE RESET BUG\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST 3: BREAKEVEN / BALANCE RESET BUG\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nRunning 5 complete episodes to check balance persistence...\\n\")\n",
        "\n",
        "episode_data = []\n",
        "\n",
        "for ep in range(5):\n",
        "    obs, info = test_env.reset()\n",
        "\n",
        "    starting_balance = test_env.balance\n",
        "\n",
        "    # Run episode\n",
        "    total_reward = 0\n",
        "    trades_executed = 0\n",
        "\n",
        "    for step in range(1000):\n",
        "        action = np.random.randn(25).astype(np.float32)\n",
        "        obs, reward, done, truncated, info = test_env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        # Count trades\n",
        "        if hasattr(test_env, 'trades_this_episode'):\n",
        "            trades_executed = len(test_env.trades_this_episode)\n",
        "\n",
        "        if done or truncated:\n",
        "            break\n",
        "\n",
        "    final_balance = test_env.balance\n",
        "    pnl = final_balance - starting_balance\n",
        "\n",
        "    episode_data.append({\n",
        "        'episode': ep + 1,\n",
        "        'start_balance': starting_balance,\n",
        "        'final_balance': final_balance,\n",
        "        'pnl': pnl,\n",
        "        'trades': trades_executed,\n",
        "        'total_reward': total_reward\n",
        "    })\n",
        "\n",
        "    print(f\"Episode {ep+1}: Start=${starting_balance:8.2f} ‚Üí End=${final_balance:8.2f} | \"\n",
        "          f\"P&L=${pnl:+8.2f} | Trades={trades_executed}\")\n",
        "\n",
        "# Analysis\n",
        "print(f\"\\nAnalysis:\")\n",
        "\n",
        "# Check if balances reset to 1000\n",
        "resets_to_1000 = sum(1 for e in episode_data if abs(e['final_balance'] - 1000.0) < 0.01)\n",
        "print(f\"  Episodes ending at exactly $1,000: {resets_to_1000}/5\")\n",
        "\n",
        "# Check if next episode starts with previous episode's final balance\n",
        "balance_carries_forward = True\n",
        "for i in range(1, len(episode_data)):\n",
        "    prev_final = episode_data[i-1]['final_balance']\n",
        "    curr_start = episode_data[i]['start_balance']\n",
        "    if abs(prev_final - curr_start) > 0.01:\n",
        "        balance_carries_forward = False\n",
        "        print(f\"  Episode {i+1} started with ${curr_start:.2f} but Episode {i} ended with ${prev_final:.2f}\")\n",
        "        break\n",
        "\n",
        "# Check for breakeven with trades\n",
        "breakeven_with_trades = [e for e in episode_data if abs(e['pnl']) < 0.01 and e['trades'] > 10]\n",
        "\n",
        "# Diagnosis\n",
        "if resets_to_1000 >= 3:\n",
        "    print(f\"\\n‚ùå BUG DETECTED: BREAKEVEN RESET BUG!\")\n",
        "    print(f\"   {resets_to_1000}/5 episodes ended at exactly $1,000\")\n",
        "    print(f\"   This suggests balance is being reset instead of calculated\")\n",
        "    print(f\"\\n   üîç Check in MarketMakingEnv.reset():\")\n",
        "    print(f\"      - Does reset() set self.balance = 1000?\")\n",
        "    print(f\"      - Should it carry forward from previous episode?\")\n",
        "    print(f\"      - Check position settlement logic\")\n",
        "\n",
        "if not balance_carries_forward:\n",
        "    print(f\"\\n‚ùå BUG DETECTED: Balance NOT carrying forward between episodes!\")\n",
        "    print(f\"   Each episode resets to a fixed value\")\n",
        "    print(f\"\\n   üîç This explains the total P&L mismatch!\")\n",
        "    print(f\"      - Episodes should start where previous ended\")\n",
        "    print(f\"      - Check MarketMakingEnv.reset() logic\")\n",
        "\n",
        "if len(breakeven_with_trades) > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: Found {len(breakeven_with_trades)} episodes with >10 trades but $0 P&L\")\n",
        "    for e in breakeven_with_trades:\n",
        "        print(f\"      Episode {e['episode']}: {e['trades']} trades ‚Üí ${e['pnl']:.2f} P&L\")\n",
        "    print(f\"   This is highly suspicious - check position settlement\")\n",
        "\n",
        "if resets_to_1000 < 2 and balance_carries_forward:\n",
        "    print(f\"\\n‚úÖ Balance reset appears to be working correctly\")\n",
        "    print(f\"   Balances carry forward between episodes\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEST 4: VALIDATION CALLBACK ISSUES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST 4: VALIDATION CALLBACK ISSUES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nTesting validation environment access...\\n\")\n",
        "\n",
        "# Check if validation environment exists\n",
        "if 'val_env' not in globals():\n",
        "    print(f\"‚ùå ERROR: val_env not found!\")\n",
        "    print(f\"   Validation environment wasn't created\")\n",
        "else:\n",
        "    print(f\"‚úÖ Validation environment exists\")\n",
        "\n",
        "    # Check if it's wrapped\n",
        "    print(f\"\\nChecking environment wrapper structure:\")\n",
        "\n",
        "    current_env = val_env\n",
        "    wrapper_chain = []\n",
        "    depth = 0\n",
        "\n",
        "    while True:\n",
        "        wrapper_chain.append(type(current_env).__name__)\n",
        "        print(f\"  Level {depth}: {type(current_env).__name__}\")\n",
        "\n",
        "        if hasattr(current_env, 'env'):\n",
        "            current_env = current_env.env\n",
        "            depth += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Test direct access\n",
        "    print(f\"\\nTesting direct attribute access on val_env:\")\n",
        "\n",
        "    test_attributes = [\n",
        "        'trades_this_episode',\n",
        "        'balance',\n",
        "        'current_race_df',\n",
        "        'step_count'\n",
        "    ]\n",
        "\n",
        "    direct_access_works = {}\n",
        "\n",
        "    for attr in test_attributes:\n",
        "        try:\n",
        "            value = getattr(val_env, attr, None)\n",
        "            direct_access_works[attr] = value is not None\n",
        "            print(f\"  val_env.{attr}: {'‚úÖ Accessible' if value is not None else '‚ö†Ô∏è  Returns None'}\")\n",
        "        except AttributeError as e:\n",
        "            direct_access_works[attr] = False\n",
        "            print(f\"  val_env.{attr}: ‚ùå AttributeError\")\n",
        "\n",
        "    # Test unwrapped access\n",
        "    print(f\"\\nTesting unwrapped attribute access:\")\n",
        "\n",
        "    unwrapped_env = val_env\n",
        "    while hasattr(unwrapped_env, 'env'):\n",
        "        unwrapped_env = unwrapped_env.env\n",
        "\n",
        "    unwrapped_access_works = {}\n",
        "\n",
        "    for attr in test_attributes:\n",
        "        try:\n",
        "            value = getattr(unwrapped_env, attr, None)\n",
        "            unwrapped_access_works[attr] = value is not None\n",
        "            print(f\"  unwrapped_env.{attr}: {'‚úÖ Accessible' if value is not None else '‚ö†Ô∏è  Returns None'}\")\n",
        "        except AttributeError as e:\n",
        "            unwrapped_access_works[attr] = False\n",
        "            print(f\"  unwrapped_env.{attr}: ‚ùå AttributeError\")\n",
        "\n",
        "    # Diagnosis\n",
        "    print(f\"\\nDiagnosis:\")\n",
        "\n",
        "    if 'Monitor' in wrapper_chain:\n",
        "        print(f\"  ‚úÖ Validation environment IS wrapped in Monitor (as expected)\")\n",
        "\n",
        "    critical_attrs = ['trades_this_episode', 'balance']\n",
        "    direct_fails = [attr for attr in critical_attrs if not direct_access_works.get(attr, False)]\n",
        "    unwrapped_works = [attr for attr in critical_attrs if unwrapped_access_works.get(attr, False)]\n",
        "\n",
        "    if len(direct_fails) > 0 and len(unwrapped_works) > 0:\n",
        "        print(f\"\\n‚ùå BUG DETECTED: VALIDATION CALLBACK WRAPPER ISSUE!\")\n",
        "        print(f\"   Direct access fails for: {direct_fails}\")\n",
        "        print(f\"   But unwrapped access works for: {unwrapped_works}\")\n",
        "        print(f\"\\n   üîç Fix in ValidationCallback:\")\n",
        "        print(f\"      Add unwrapping logic:\")\n",
        "        print(f\"      ```python\")\n",
        "        print(f\"      env = self.val_env\")\n",
        "        print(f\"      while hasattr(env, 'env'):\")\n",
        "        print(f\"          env = env.env\")\n",
        "        print(f\"      trades = env.trades_this_episode\")\n",
        "        print(f\"      ```\")\n",
        "    elif len(unwrapped_works) == len(critical_attrs):\n",
        "        print(f\"  ‚úÖ Unwrapped access works for all critical attributes\")\n",
        "        print(f\"  ‚ö†Ô∏è  But ValidationCallback needs to unwrap to access them\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  Some attributes not accessible even when unwrapped\")\n",
        "        print(f\"     This might be expected before reset() is called\")\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä DIAGNOSTIC SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüîç Bugs Found:\")\n",
        "\n",
        "bugs_found = []\n",
        "\n",
        "# MTM check\n",
        "if sum(1 for r in mtm_rewards if abs(r) > 1e-6) == 0:\n",
        "    bugs_found.append(\"‚ùå MTM Rewards: ALL ZERO (0% working)\")\n",
        "\n",
        "# Sharpe check\n",
        "if sum(1 for r in sharpe_rewards if abs(r) > 1e-6) == 0:\n",
        "    bugs_found.append(\"‚ùå Sharpe Rewards: ALL ZERO (0% working)\")\n",
        "\n",
        "# Breakeven check\n",
        "if resets_to_1000 >= 3:\n",
        "    bugs_found.append(f\"‚ùå Breakeven Reset: {resets_to_1000}/5 episodes reset to $1,000\")\n",
        "\n",
        "# Validation check\n",
        "if len(direct_fails) > 0 and len(unwrapped_works) > 0:\n",
        "    bugs_found.append(\"‚ùå Validation Callback: Monitor unwrapping needed\")\n",
        "\n",
        "if len(bugs_found) == 0:\n",
        "    print(f\"\\n‚úÖ NO CRITICAL BUGS DETECTED!\")\n",
        "    print(f\"   All systems appear to be working correctly\")\n",
        "else:\n",
        "    for bug in bugs_found:\n",
        "        print(f\"  {bug}\")\n",
        "\n",
        "    print(f\"\\n‚ö†Ô∏è  TOTAL BUGS FOUND: {len(bugs_found)}\")\n",
        "    print(f\"\\nüîß RECOMMENDED ACTIONS:\")\n",
        "    print(f\"   1. Fix each bug listed above\")\n",
        "    print(f\"   2. Re-run this diagnostic cell\")\n",
        "    print(f\"   3. Verify all tests pass\")\n",
        "    print(f\"   4. THEN start training\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ DIAGNOSTIC COMPLETE\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "mLRamPm5nww2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATA STRUCTURE DIAGNOSTIC - Run this in Colab\n",
        "# ============================================================================\n",
        "#\n",
        "# PURPOSE: Check what columns your data actually has\n",
        "# This will tell us which fix to apply\n",
        "#\n",
        "# INSTRUCTIONS:\n",
        "# 1. In Colab, create a new cell after Cell 4 (data loading)\n",
        "# 2. Copy-paste this entire code\n",
        "# 3. Run the cell\n",
        "# 4. Share the output to get the right fix\n",
        "#\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîç DATA STRUCTURE DIAGNOSTIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load one sample file\n",
        "import pandas as pd\n",
        "\n",
        "if len(train_files) == 0:\n",
        "    print(\"\\n‚ùå ERROR: No training files loaded!\")\n",
        "    print(\"   Make sure Cell 4 (data loading) ran successfully\")\n",
        "else:\n",
        "    print(f\"\\n‚úì Found {len(train_files)} training files\")\n",
        "\n",
        "    # Load first file\n",
        "    sample_file = train_files[0]\n",
        "    print(f\"\\nüìÇ Analyzing: {sample_file.split('/')[-1]}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_parquet(sample_file)\n",
        "        print(f\"‚úì Loaded {len(df)} rows\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CHECKING RUNNER 0 COLUMNS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Get all columns for runner 0\n",
        "        runner0_cols = [col for col in df.columns if col.startswith('run[0].')]\n",
        "\n",
        "        if len(runner0_cols) == 0:\n",
        "            print(\"\\n‚ùå No run[0]. columns found!\")\n",
        "            print(\"   Your data might use a different format\")\n",
        "            print(\"\\n   Available columns sample:\")\n",
        "            for col in list(df.columns)[:20]:\n",
        "                print(f\"     {col}\")\n",
        "        else:\n",
        "            print(f\"\\n‚úì Found {len(runner0_cols)} columns for runner 0\")\n",
        "\n",
        "            # Check for critical columns\n",
        "            critical_checks = {\n",
        "                'Prices': ['run[0].back_price_1', 'run[0].lay_price_1'],\n",
        "                'Volume L1': ['run[0].back_vol_1', 'run[0].lay_vol_1'],\n",
        "                'Volume L2': ['run[0].back_vol_2', 'run[0].lay_vol_2'],\n",
        "                'Volume L3': ['run[0].back_vol_3', 'run[0].lay_vol_3'],\n",
        "                'Last Traded': ['run[0].ltp', 'run[0].ltv'],\n",
        "                'Total Matched': ['run[0].total_matched'],\n",
        "            }\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"CRITICAL FEATURES CHECK\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            results = {}\n",
        "            for category, cols in critical_checks.items():\n",
        "                has_all = all(col in df.columns for col in cols)\n",
        "                results[category] = has_all\n",
        "\n",
        "                status = \"‚úì\" if has_all else \"‚ùå\"\n",
        "                print(f\"\\n{status} {category}:\")\n",
        "                for col in cols:\n",
        "                    exists = \"‚úì\" if col in df.columns else \"‚ùå\"\n",
        "                    print(f\"   {exists} {col}\")\n",
        "\n",
        "            # Determine which solution to use\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"üìä SOLUTION RECOMMENDATION\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            has_prices = results['Prices']\n",
        "            has_vol1 = results['Volume L1']\n",
        "            has_vol2 = results['Volume L2']\n",
        "            has_vol3 = results['Volume L3']\n",
        "\n",
        "            if has_prices and has_vol1 and has_vol2 and has_vol3:\n",
        "                print(\"\\n‚úÖ SOLUTION A: EXPAND get_runner_data()\")\n",
        "                print(\"   Your data HAS all depth levels (vol_1, vol_2, vol_3)\")\n",
        "                print(\"   I'll create a Cell 5 fix to extract all levels\")\n",
        "                solution = \"A\"\n",
        "\n",
        "            elif has_prices and has_vol1:\n",
        "                print(\"\\n‚ö†Ô∏è  SOLUTION C: PAD WITH ZEROS\")\n",
        "                print(\"   Your data only has vol_1 (no vol_2, vol_3)\")\n",
        "                print(\"   I'll create a Cell 7 fix to pad missing features\")\n",
        "                solution = \"C\"\n",
        "\n",
        "            else:\n",
        "                print(\"\\n‚ùå CRITICAL: Missing essential columns\")\n",
        "                print(\"   Cannot determine solution without price/volume data\")\n",
        "                solution = \"UNKNOWN\"\n",
        "\n",
        "            # Show full column list\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(f\"ALL RUNNER 0 COLUMNS ({len(runner0_cols)})\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for col in sorted(runner0_cols):\n",
        "                print(f\"  {col}\")\n",
        "\n",
        "            # Summary\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"üìã SUMMARY\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            print(f\"\\nData file: {sample_file.split('/')[-1]}\")\n",
        "            print(f\"Rows: {len(df)}\")\n",
        "            print(f\"Total columns: {len(df.columns)}\")\n",
        "            print(f\"Runner 0 columns: {len(runner0_cols)}\")\n",
        "            print(f\"\\nRecommended solution: {solution}\")\n",
        "\n",
        "            if solution == \"A\":\n",
        "                print(\"\\n‚úÖ Next step: Apply Cell 5 fix (expand data extraction)\")\n",
        "            elif solution == \"C\":\n",
        "                print(\"\\n‚úÖ Next step: Apply Cell 7 fix (pad with zeros)\")\n",
        "            else:\n",
        "                print(\"\\n‚ùå Need to investigate data structure further\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR loading file: {e}\")\n",
        "        print(\"\\n   Try checking if the file path is correct\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "MBzP_2lY03eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load a sample file\n",
        "sample_file = '/content/drive/MyDrive/Betfair_RL/race_out/2026-01-12_Gawler_Race8_1.252604001.parquet'\n",
        "df = pd.read_parquet(sample_file)\n",
        "\n",
        "print(\"Testing get_runner_data() with corrected column names:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get first row\n",
        "row = df.iloc[0]\n",
        "\n",
        "# Test runner 0\n",
        "runner_data = get_runner_data(row, 0)\n",
        "\n",
        "if runner_data:\n",
        "    print(\"\\n‚úÖ SUCCESS: Data extracted correctly!\")\n",
        "    print(f\"\\nRunner 0 data:\")\n",
        "    for key, value in runner_data.items():\n",
        "        print(f\"  {key:15s}: {value:.4f}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå FAILED: Could not extract runner data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "vEjAuy3kFmiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_file = getattr(env, 'current_race_file', None)\n",
        "if race_file:\n",
        "    print(f\"  Race: {race_file.split('/')[-1]}\")\n",
        "else:\n",
        "    print(f\"  Race: (file path not stored)\")"
      ],
      "metadata": {
        "id": "VlL9RiFGD7hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjuis4lbZaHq"
      },
      "outputs": [],
      "source": [
        "### CELL 6 - TRAIN MODEL ###\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ Starting V42 training run (Green-Up Strategy)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training for {CURRICULUM_TOTAL_STEPS:,} steps\")\n",
        "print(f\"Expected duration: ~4-6 hours\")\n",
        "print(f\"Output directory: {BASE_PATH}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=CURRICULUM_TOTAL_STEPS,\n",
        "    callback=callbacks,\n",
        "    progress_bar=False\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "final_model_path = f\"{BASE_PATH}/final_model\"\n",
        "model.save(final_model_path)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ Training complete!\")\n",
        "print(f\"üíæ Final model saved: {final_model_path}\")\n",
        "print(f\"üìä Metrics saved to: {BASE_PATH}/\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_WbxzGUAxNJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}